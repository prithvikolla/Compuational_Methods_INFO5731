{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "In_class_exercise_07.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTF8z9oiMYS4"
      },
      "source": [
        "# **The seventh in-class-exercise (20 points in total, 10/21/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiHkozK0MYS5"
      },
      "source": [
        "Question description: In the last in-class-exercise (exercise-06), you collected the titles of 100 articles about data science, natural language processing, and machine learning. The 100 article titles will be used as the text corpus of this exercise. Perform the following tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvjttOMyMYS6"
      },
      "source": [
        "## (1) (8 points) Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here: \n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StxxCYl8Yf7d",
        "outputId": "64eecf6a-c4af-41bf-c7b0-4de18bd5c739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.15)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.1.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.35.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.11.2)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (50.3.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (20.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (8.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov515BIBMYS6",
        "outputId": "70b5f48c-fe49-4667-b009-ffa2ec1c0218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "import nltk\n",
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "import re\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obCCMy9qXT_q",
        "outputId": "11deba68-cc69-43df-addf-747da729684d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv('/content/titles.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Foundations of statistical natural language pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Natural language processing with Python: analy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Stanford CoreNLP natural language processi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Handbook of natural language processing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Natural language processing (almost) from scratch</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Titles\n",
              "0  Foundations of statistical natural language pr...\n",
              "1  Natural language processing with Python: analy...\n",
              "2  The Stanford CoreNLP natural language processi...\n",
              "3            Handbook of natural language processing\n",
              "4  Natural language processing (almost) from scratch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ApPwtUWZINW"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "#1 Noise removal\n",
        "df['Titles'] = df['Titles'].replace('\\n','',regex = True)\n",
        "df['Titles'] = df['Titles'].replace('[^\\w\\s]','',regex = True)\n",
        "\n",
        "#2 Remove numbers\n",
        "df['Titles'] = df['Titles'].str.replace('\\d+','')\n",
        "df['Titles'] = df['Titles'].str.replace('\\d+','')\n",
        "#3 Remove StopWords\n",
        "stop_Words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \n",
        "              \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
        "              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\",\n",
        "              \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\",\n",
        "              \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\",\n",
        "              \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\",\n",
        "              \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\",\n",
        "              \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\",\n",
        "              \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\",\n",
        "              \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\",\n",
        "              \"about\", \"against\", \"between\", \"into\", \"through\",\n",
        "              \"during\", \"before\", \"after\", \"above\", \"below\", \"to\",\n",
        "              \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\",\n",
        "              \"under\", \"again\", \"further\", \"then\", \"once\", \"here\",\n",
        "              \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\",\n",
        "              \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\",\n",
        "              \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\",\n",
        "              \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\",\n",
        "              \"don\", \"should\", \"now\"]\n",
        "# stop = stopwords.words('english')\n",
        "df['Titles'] = df['Titles'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_Words))\n",
        "#4 Lowercase all text\n",
        "df['Titles'] = df['Titles'].str.lower()\n",
        "#5 Stemming\n",
        "df['Titles'] = df['Titles'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "#6 Lemmatization\n",
        "df['Titles']=df['Titles'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrRUbgsldGF6",
        "outputId": "22a02859-c5b0-456d-fde1-a99a5bdc692e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>foundat statist natur languag process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>natur languag process python analyz text natur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the stanford corenlp natur languag process too...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>handbook natur languag process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>natur languag process almost scratch</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Titles\n",
              "0              foundat statist natur languag process\n",
              "1  natur languag process python analyz text natur...\n",
              "2  the stanford corenlp natur languag process too...\n",
              "3                     handbook natur languag process\n",
              "4               natur languag process almost scratch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loTIps_R2fuS"
      },
      "source": [
        "data = df.Titles.values.tolist()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vp3ongt2fyE",
        "outputId": "48116d65-dd47-419a-a191-b3e93f0bdbbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "data_words = list(sent_to_words(data))\n",
        "print(data_words[:1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['foundat', 'statist', 'natur', 'languag', 'process']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nzvqD7t2f2t",
        "outputId": "fbe33e01-bafd-431a-d3d4-72a35d012265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=2) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=2)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "\n",
        "print(trigram_mod[bigram_mod[data_words[1]]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['natur_languag_process', 'python', 'analyz', 'text', 'natur_languag', 'toolkit']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FLlUpFr2f8F"
      },
      "source": [
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "  \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "  texts_out = []\n",
        "  for sent in texts:\n",
        "      doc = nlp(\" \".join(sent)) \n",
        "      texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "  return texts_out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN8De5F_2f_2"
      },
      "source": [
        "data_words_trigrams = make_trigrams(data_words)\n",
        "data_words_bigrams = make_bigrams(data_words)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsaDFPeU2f6R"
      },
      "source": [
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnRKGqQj2f1Y",
        "outputId": "96a35e3e-5e9c-4d87-cba2-d7eaef4df3c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized_trigrams = lemmatization(data_words_trigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "data_lemmatized_bigrams = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "print(data_lemmatized_bigrams[:10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['process'], ['process', 'text', 'toolkit'], ['corenlp', 'process', 'toolkit'], ['process'], ['process', 'almost', 'scratch'], ['approach', 'process'], ['process'], ['read', 'process'], ['recent', 'trend', 'deep', 'learn', 'base', 'process'], ['process', 'deep', 'neural', 'network', 'multitask', 'learn']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxG0sN7jFlQz",
        "outputId": "b9b4685b-5fc8-434a-c2ae-be9987510ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized_bigrams)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized_bigrams\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-BZKq96FlTp",
        "outputId": "9572743d-178f-454b-ea4e-70b1c2df7429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "id2word[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'process'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwKs6eG5FlZF",
        "outputId": "894b0189-40d3-4d3c-9451-79ce03d94295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:10]]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('process', 1)],\n",
              " [('process', 1), ('text', 1), ('toolkit', 1)],\n",
              " [('process', 1), ('toolkit', 1), ('corenlp', 1)],\n",
              " [('process', 1)],\n",
              " [('process', 1), ('almost', 1), ('scratch', 1)],\n",
              " [('process', 1), ('approach', 1)],\n",
              " [('process', 1)],\n",
              " [('process', 1), ('read', 1)],\n",
              " [('process', 1),\n",
              "  ('base', 1),\n",
              "  ('deep', 1),\n",
              "  ('learn', 1),\n",
              "  ('recent', 1),\n",
              "  ('trend', 1)],\n",
              " [('process', 1),\n",
              "  ('deep', 1),\n",
              "  ('learn', 1),\n",
              "  ('multitask', 1),\n",
              "  ('network', 1),\n",
              "  ('neural', 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfxoSP_d17Ex"
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=100, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swA_XjWN17Im",
        "outputId": "32464f44-a624-4e9c-c4fb-9bdbc9eb5c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(11,\n",
            "  '0.008*\"related\" + 0.008*\"modular\" + 0.008*\"thereof\" + 0.008*\"comput\" + '\n",
            "  '0.008*\"handbook\" + 0.008*\"linguist\" + 0.008*\"medicin\" + 0.008*\"kind\" + '\n",
            "  '0.008*\"record\" + 0.008*\"problem\"'),\n",
            " (36,\n",
            "  '0.008*\"related\" + 0.008*\"modular\" + 0.008*\"thereof\" + 0.008*\"comput\" + '\n",
            "  '0.008*\"handbook\" + 0.008*\"linguist\" + 0.008*\"medicin\" + 0.008*\"kind\" + '\n",
            "  '0.008*\"record\" + 0.008*\"problem\"'),\n",
            " (87,\n",
            "  '0.008*\"related\" + 0.008*\"modular\" + 0.008*\"thereof\" + 0.008*\"comput\" + '\n",
            "  '0.008*\"handbook\" + 0.008*\"linguist\" + 0.008*\"medicin\" + 0.008*\"kind\" + '\n",
            "  '0.008*\"record\" + 0.008*\"problem\"'),\n",
            " (9,\n",
            "  '0.008*\"related\" + 0.008*\"modular\" + 0.008*\"thereof\" + 0.008*\"comput\" + '\n",
            "  '0.008*\"handbook\" + 0.008*\"linguist\" + 0.008*\"medicin\" + 0.008*\"kind\" + '\n",
            "  '0.008*\"record\" + 0.008*\"problem\"'),\n",
            " (75,\n",
            "  '0.008*\"related\" + 0.008*\"modular\" + 0.008*\"thereof\" + 0.008*\"comput\" + '\n",
            "  '0.008*\"handbook\" + 0.008*\"linguist\" + 0.008*\"medicin\" + 0.008*\"kind\" + '\n",
            "  '0.008*\"record\" + 0.008*\"problem\"'),\n",
            " (13,\n",
            "  '0.008*\"related\" + 0.008*\"modular\" + 0.008*\"thereof\" + 0.008*\"comput\" + '\n",
            "  '0.008*\"handbook\" + 0.008*\"linguist\" + 0.008*\"medicin\" + 0.008*\"kind\" + '\n",
            "  '0.008*\"record\" + 0.008*\"problem\"'),\n",
            " (6,\n",
            "  '0.008*\"related\" + 0.008*\"modular\" + 0.008*\"thereof\" + 0.008*\"comput\" + '\n",
            "  '0.008*\"handbook\" + 0.008*\"linguist\" + 0.008*\"medicin\" + 0.008*\"kind\" + '\n",
            "  '0.008*\"record\" + 0.008*\"problem\"'),\n",
            " (94,\n",
            "  '0.008*\"related\" + 0.008*\"modular\" + 0.008*\"thereof\" + 0.008*\"comput\" + '\n",
            "  '0.008*\"handbook\" + 0.008*\"linguist\" + 0.008*\"medicin\" + 0.008*\"kind\" + '\n",
            "  '0.008*\"record\" + 0.008*\"problem\"'),\n",
            " (93,\n",
            "  '0.008*\"related\" + 0.008*\"modular\" + 0.008*\"thereof\" + 0.008*\"comput\" + '\n",
            "  '0.008*\"handbook\" + 0.008*\"linguist\" + 0.008*\"medicin\" + 0.008*\"kind\" + '\n",
            "  '0.008*\"record\" + 0.008*\"problem\"'),\n",
            " (77,\n",
            "  '0.008*\"related\" + 0.008*\"modular\" + 0.008*\"thereof\" + 0.008*\"comput\" + '\n",
            "  '0.008*\"handbook\" + 0.008*\"linguist\" + 0.008*\"medicin\" + 0.008*\"kind\" + '\n",
            "  '0.008*\"record\" + 0.008*\"problem\"'),\n",
            " (40,\n",
            "  '0.323*\"process\" + 0.158*\"term\" + 0.158*\"overview\" + 0.158*\"empir\" + '\n",
            "  '0.003*\"inform\" + 0.003*\"retriev\" + 0.002*\"medicin\" + 0.002*\"pdp\" + '\n",
            "  '0.002*\"related\" + 0.002*\"linguist\"'),\n",
            " (73,\n",
            "  '0.244*\"process\" + 0.163*\"learn\" + 0.163*\"deep\" + 0.082*\"base\" + '\n",
            "  '0.082*\"trend\" + 0.082*\"recent\" + 0.082*\"arab\" + 0.001*\"linguist\" + '\n",
            "  '0.001*\"comput\" + 0.001*\"related\"'),\n",
            " (8,\n",
            "  '0.361*\"process\" + 0.241*\"approach\" + 0.122*\"drama\" + 0.122*\"charact\" + '\n",
            "  '0.001*\"medicin\" + 0.001*\"postop\" + 0.001*\"thereof\" + 0.001*\"comput\" + '\n",
            "  '0.001*\"handbook\" + 0.001*\"linguist\"'),\n",
            " (48,\n",
            "  '0.279*\"process\" + 0.220*\"base\" + 0.136*\"system\" + 0.111*\"sentenc\" + '\n",
            "  '0.111*\"advanc\" + 0.002*\"detect\" + 0.002*\"use\" + 0.001*\"linguist\" + '\n",
            "  '0.001*\"medicin\" + 0.001*\"related\"'),\n",
            " (44,\n",
            "  '0.239*\"process\" + 0.152*\"review\" + 0.084*\"use\" + 0.084*\"favor\" + '\n",
            "  '0.084*\"radiolog\" + 0.084*\"systemat\" + 0.084*\"opinion\" + 0.084*\"mine\" + '\n",
            "  '0.001*\"system\" + 0.001*\"medicin\"'),\n",
            " (65,\n",
            "  '0.363*\"process\" + 0.121*\"base\" + 0.121*\"document\" + 0.121*\"strategi\" + '\n",
            "  '0.121*\"appli\" + 0.002*\"approach\" + 0.001*\"linguist\" + 0.001*\"medicin\" + '\n",
            "  '0.001*\"related\" + 0.001*\"modular\"'),\n",
            " (89,\n",
            "  '0.247*\"process\" + 0.062*\"support\" + 0.062*\"kind\" + 0.062*\"space\" + '\n",
            "  '0.062*\"inform\" + 0.062*\"system\" + 0.062*\"thereof\" + 0.062*\"predict\" + '\n",
            "  '0.062*\"clinic\" + 0.062*\"decis\"'),\n",
            " (2,\n",
            "  '0.259*\"process\" + 0.216*\"network\" + 0.144*\"neural\" + 0.073*\"convolut\" + '\n",
            "  '0.073*\"method\" + 0.073*\"modular\" + 0.073*\"pdp\" + 0.001*\"handbook\" + '\n",
            "  '0.001*\"linguist\" + 0.001*\"medicin\"'),\n",
            " (25,\n",
            "  '0.366*\"process\" + 0.260*\"model\" + 0.174*\"text\" + 0.088*\"mine\" + '\n",
            "  '0.001*\"comput\" + 0.001*\"handbook\" + 0.001*\"linguist\" + 0.001*\"medicin\" + '\n",
            "  '0.001*\"related\" + 0.001*\"thereof\"'),\n",
            " (42,\n",
            "  '0.817*\"process\" + 0.056*\"programm\" + 0.056*\"prolog\" + 0.001*\"related\" + '\n",
            "  '0.001*\"postop\" + 0.001*\"comput\" + 0.001*\"handbook\" + 0.001*\"linguist\" + '\n",
            "  '0.001*\"medicin\" + 0.001*\"predict\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdsUtpSr17O_",
        "outputId": "c1876120-8a44-466b-a6ed-5cc9e374eed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized_bigrams, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -6.498916633654295\n",
            "\n",
            "Coherence Score:  0.6806093326364346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gUFV8g417NB",
        "outputId": "ebee9ef9-9984-4be4-98f3-8bc9f88b203b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "# Visualize the topics\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word,mds='mmds')\n",
        "vis"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster      Freq\n",
              "topic                                               \n",
              "89    -0.136293  0.298384       1        1  4.112397\n",
              "60    -0.356289 -0.006825       2        1  3.675375\n",
              "2     -0.213833  0.290073       3        1  3.244261\n",
              "57     0.218162  0.326261       4        1  3.214141\n",
              "42    -0.064422  0.375580       5        1  3.198078\n",
              "...         ...       ...     ...      ...       ...\n",
              "56     0.016602 -0.142358      96        1  0.205696\n",
              "58     0.016602 -0.142358      97        1  0.205696\n",
              "59     0.016602 -0.142358      98        1  0.205696\n",
              "61     0.016602 -0.142358      99        1  0.205696\n",
              "0      0.016602 -0.142358     100        1  0.205696\n",
              "\n",
              "[100 rows x 5 columns], topic_info=        Term       Freq      Total  Category  logprob  loglift\n",
              "0    process  74.000000  74.000000   Default  30.0000  30.0000\n",
              "44    system  13.000000  13.000000   Default  29.0000  29.0000\n",
              "19       use   8.000000   8.000000   Default  28.0000  28.0000\n",
              "10     learn   5.000000   5.000000   Default  27.0000  27.0000\n",
              "38    method   5.000000   5.000000   Default  26.0000  26.0000\n",
              "..       ...        ...        ...       ...      ...      ...\n",
              "56   weather   0.005073   1.390264  Topic100  -4.8903   0.5732\n",
              "57    clinic   0.005073   2.179934  Topic100  -4.8903   0.1234\n",
              "58     decis   0.005073   1.443212  Topic100  -4.8903   0.5358\n",
              "59   support   0.005073   1.443212  Topic100  -4.8903   0.5358\n",
              "61  paninian   0.005073   1.427172  Topic100  -4.8903   0.5470\n",
              "\n",
              "[5065 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "74        2  0.684813   account\n",
              "22       18  0.739891    advanc\n",
              "120      17  0.693467     adver\n",
              "110       6  0.693640  advertis\n",
              "4        42  0.765775    almost\n",
              "...     ...       ...       ...\n",
              "19       48  0.120015       use\n",
              "51        4  0.657970      user\n",
              "76        2  0.684813    vector\n",
              "56       16  0.719288   weather\n",
              "131      28  0.718222      word\n",
              "\n",
              "[243 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[90, 61, 3, 58, 43, 73, 74, 45, 18, 93, 26, 8, 70, 27, 79, 52, 23, 49, 21, 65, 55, 84, 66, 9, 50, 6, 96, 24, 11, 35, 25, 41, 87, 85, 36, 17, 54, 33, 71, 30, 13, 22, 56, 31, 83, 15, 69, 77, 4, 16, 97, 19, 14, 7, 5, 20, 28, 29, 10, 2, 32, 12, 34, 100, 37, 38, 72, 75, 76, 78, 80, 81, 82, 86, 88, 89, 91, 92, 94, 95, 98, 68, 67, 64, 48, 39, 40, 42, 44, 46, 47, 99, 63, 51, 53, 57, 59, 60, 62, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxVyu6q1Dm6j",
        "outputId": "f1cfd377-4bca-42eb-8236-3325f73d62b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!pip install smart_open "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart_open) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart_open) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW-tt8WjDnAN",
        "outputId": "d936b2d3-124f-44d1-aed5-c407b94853b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "help('smart_open')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on package smart_open:\n",
            "\n",
            "NAME\n",
            "    smart_open\n",
            "\n",
            "DESCRIPTION\n",
            "    Utilities for streaming to/from several file-like data storages: S3 / HDFS / local\n",
            "    filesystem / compressed files, and many more, using a simple, Pythonic API.\n",
            "    \n",
            "    The streaming makes heavy use of generators and pipes, to avoid loading\n",
            "    full file contents into memory, allowing work with arbitrarily large files.\n",
            "    \n",
            "    The main functions are:\n",
            "    \n",
            "    * `open()`, which opens the given file for reading/writing\n",
            "    * `parse_uri()`\n",
            "    * `s3_iter_bucket()`, which goes over all keys in an S3 bucket in parallel\n",
            "    * `register_compressor()`, which registers callbacks for transparent compressor handling\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    azure\n",
            "    bytebuffer\n",
            "    compression\n",
            "    concurrency\n",
            "    constants\n",
            "    doctools\n",
            "    gcs\n",
            "    hdfs\n",
            "    http\n",
            "    local_file\n",
            "    s3\n",
            "    smart_open_lib\n",
            "    ssh\n",
            "    tests (package)\n",
            "    transport\n",
            "    utils\n",
            "    version\n",
            "    webhdfs\n",
            "\n",
            "FUNCTIONS\n",
            "    open(uri, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None, ignore_ext=False, transport_params=None)\n",
            "        Open the URI object, returning a file-like object.\n",
            "        \n",
            "        The URI is usually a string in a variety of formats.\n",
            "        For a full list of examples, see the :func:`parse_uri` function.\n",
            "        \n",
            "        The URI may also be one of:\n",
            "        \n",
            "        - an instance of the pathlib.Path class\n",
            "        - a stream (anything that implements io.IOBase-like functionality)\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        uri: str or object\n",
            "            The object to open.\n",
            "        mode: str, optional\n",
            "            Mimicks built-in open parameter of the same name.\n",
            "        buffering: int, optional\n",
            "            Mimicks built-in open parameter of the same name.\n",
            "        encoding: str, optional\n",
            "            Mimicks built-in open parameter of the same name.\n",
            "        errors: str, optional\n",
            "            Mimicks built-in open parameter of the same name.\n",
            "        newline: str, optional\n",
            "            Mimicks built-in open parameter of the same name.\n",
            "        closefd: boolean, optional\n",
            "            Mimicks built-in open parameter of the same name.  Ignored.\n",
            "        opener: object, optional\n",
            "            Mimicks built-in open parameter of the same name.  Ignored.\n",
            "        ignore_ext: boolean, optional\n",
            "            Disable transparent compression/decompression based on the file extension.\n",
            "        transport_params: dict, optional\n",
            "            Additional parameters for the transport layer (see notes below).\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        A file-like object.\n",
            "        \n",
            "        Notes\n",
            "        -----\n",
            "        smart_open has several implementations for its transport layer (e.g. S3, HTTP).\n",
            "        Each transport layer has a different set of keyword arguments for overriding\n",
            "        default behavior.  If you specify a keyword argument that is *not* supported\n",
            "        by the transport layer being used, smart_open will ignore that argument and\n",
            "        log a warning message.\n",
            "        \n",
            "        smart_open supports the following transport mechanisms:\n",
            "        \n",
            "        file (smart_open/local_file.py)\n",
            "        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "        Implements the transport for the file:// schema.\n",
            "        \n",
            "        gs (smart_open/gcs.py)\n",
            "        ~~~~~~~~~~~~~~~~~~~~~~\n",
            "        Implements file-like objects for reading and writing to/from GCS.\n",
            "        \n",
            "        buffer_size: int, optional\n",
            "            The buffer size to use when performing I/O. For reading only.\n",
            "        min_part_size: int, optional\n",
            "            The minimum part size for multipart uploads.  For writing only.\n",
            "        client: google.cloud.storage.Client, optional\n",
            "            The GCS client to use when working with google-cloud-storage.\n",
            "        \n",
            "        hdfs (smart_open/hdfs.py)\n",
            "        ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "        Implements reading and writing to/from HDFS.\n",
            "        \n",
            "        http (smart_open/http.py)\n",
            "        ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "        Implements file-like objects for reading from http.\n",
            "        \n",
            "        kerberos: boolean, optional\n",
            "            If True, will attempt to use the local Kerberos credentials\n",
            "        user: str, optional\n",
            "            The username for authenticating over HTTP\n",
            "        password: str, optional\n",
            "            The password for authenticating over HTTP\n",
            "        headers: dict, optional\n",
            "            Any headers to send in the request. If ``None``, the default headers are sent:\n",
            "            ``{'Accept-Encoding': 'identity'}``. To use no headers at all,\n",
            "            set this variable to an empty dict, ``{}``.\n",
            "        \n",
            "        scp (smart_open/ssh.py)\n",
            "        ~~~~~~~~~~~~~~~~~~~~~~~\n",
            "        Implements I/O streams over SSH.\n",
            "        \n",
            "        mode: str, optional\n",
            "            The mode to use for opening the file.\n",
            "        host: str, optional\n",
            "            The hostname of the remote machine.  May not be None.\n",
            "        user: str, optional\n",
            "            The username to use to login to the remote machine.\n",
            "            If None, defaults to the name of the current user.\n",
            "        password: str, optional\n",
            "            The password to use to login to the remote machine.\n",
            "        port: int, optional\n",
            "            The port to connect to.\n",
            "        transport_params: dict, optional\n",
            "            Any additional settings to be passed to paramiko.SSHClient.connect\n",
            "        \n",
            "        webhdfs (smart_open/webhdfs.py)\n",
            "        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "        Implements reading and writing to/from WebHDFS.\n",
            "        \n",
            "        min_part_size: int, optional\n",
            "            For writing only.\n",
            "        \n",
            "        Examples\n",
            "        --------\n",
            "        \n",
            "        See README.rst\n",
            "        This function also supports transparent compression and decompression \n",
            "        using the following codecs:\n",
            "        \n",
            "        * .bz2\n",
            "        * .gz\n",
            "        \n",
            "        The function depends on the file extension to determine the appropriate codec.\n",
            "        \n",
            "        \n",
            "        See Also\n",
            "        --------\n",
            "        - `Standard library reference <https://docs.python.org/3.7/library/functions.html#open>`__\n",
            "        - `smart_open README.rst\n",
            "          <https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst>`__\n",
            "    \n",
            "    parse_uri(uri_as_string)\n",
            "        Parse the given URI from a string.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        uri_as_string: str\n",
            "            The URI to parse.\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        collections.namedtuple\n",
            "            The parsed URI.\n",
            "        \n",
            "        Notes\n",
            "        -----\n",
            "        Supported URI schemes are:\n",
            "        \n",
            "        * file\n",
            "        * gs\n",
            "        * hdfs\n",
            "        * http\n",
            "        * scp\n",
            "        * webhdfs\n",
            "        \n",
            "        Valid URI examples::\n",
            "        \n",
            "        * ./local/path/file\n",
            "        * ~/local/path/file\n",
            "        * local/path/file\n",
            "        * ./local/path/file.gz\n",
            "        * file:///home/user/file\n",
            "        * file:///home/user/file.bz2\n",
            "        * hdfs:///path/file\n",
            "        * hdfs://path/file\n",
            "        * ssh://username@host/path/file\n",
            "        * ssh://username@host//path/file\n",
            "        * scp://username@host/path/file\n",
            "        * sftp://username@host/path/file\n",
            "        * webhdfs://host:port/path/file\n",
            "    \n",
            "    register_compressor(ext, callback)\n",
            "        Register a callback for transparently decompressing files with a specific extension.\n",
            "        \n",
            "        Parameters\n",
            "        ----------\n",
            "        ext: str\n",
            "            The extension.  Must include the leading period, e.g. ``.gz``.\n",
            "        callback: callable\n",
            "            The callback.  It must accept two position arguments, file_obj and mode.\n",
            "            This function will be called when ``smart_open`` is opening a file with\n",
            "            the specified extension.\n",
            "        \n",
            "        Examples\n",
            "        --------\n",
            "        \n",
            "        Instruct smart_open to use the `lzma` module whenever opening a file\n",
            "        with a .xz extension (see README.rst for the complete example showing I/O):\n",
            "        \n",
            "        >>> def _handle_xz(file_obj, mode):\n",
            "        ...     import lzma\n",
            "        ...     return lzma.LZMAFile(filename=file_obj, mode=mode, format=lzma.FORMAT_XZ)\n",
            "        >>>\n",
            "        >>> register_compressor('.xz', _handle_xz)\n",
            "    \n",
            "    s3_iter_bucket(bucket_name, prefix='', accept_key=None, key_limit=None, workers=16, retries=3, **session_kwargs)\n",
            "        Deprecated.  Use smart_open.s3.iter_bucket instead.\n",
            "    \n",
            "    smart_open(uri, mode='rb', **kw)\n",
            "\n",
            "DATA\n",
            "    __all__ = ['open', 'parse_uri', 'register_compressor', 's3_iter_bucket...\n",
            "\n",
            "VERSION\n",
            "    2.2.0\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.6/dist-packages/smart_open/__init__.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FROwUEZcDnS3",
        "outputId": "9a05e7f1-ecbb-4b00-9008-9c6e18ab0107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# !wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "# !unzip mallet-2.0.8.zip"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-23 01:55:11--  http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
            "Resolving mallet.cs.umass.edu (mallet.cs.umass.edu)... 128.119.246.70\n",
            "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16184794 (15M) [application/zip]\n",
            "Saving to: mallet-2.0.8.zip.1\n",
            "\n",
            "mallet-2.0.8.zip.1  100%[===================>]  15.43M  8.98MB/s    in 1.7s    \n",
            "\n",
            "2020-10-23 01:55:13 (8.98 MB/s) - mallet-2.0.8.zip.1 saved [16184794/16184794]\n",
            "\n",
            "Archive:  mallet-2.0.8.zip\n",
            "replace mallet-2.0.8/bin/classifier2info? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CC597KhDnVk",
        "outputId": "bca0f122-2941-4a4c-e5bc-5992dc384b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "os.environ['MALLET_HOME'] = '/content/mallet-2.0.8'\n",
        "mallet_path = '/content/mallet-2.0.8/bin/mallet' \n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=100, id2word=id2word)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izoFzhI7Dmxy",
        "outputId": "69cd69b2-380e-402d-a1db-97c88fc1c3a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Show Topics\n",
        "pprint(ldamallet.show_topics(formatted=False))\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized_bigrams, dictionary=id2word, coherence='c_v')\n",
        "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_ldamallet)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(79,\n",
            "  [('user', 0.6666666666666666),\n",
            "   ('process', 0.3333333333333333),\n",
            "   ('related', 0.0),\n",
            "   ('thereof', 0.0),\n",
            "   ('comput', 0.0),\n",
            "   ('handbook', 0.0),\n",
            "   ('linguist', 0.0),\n",
            "   ('medicin', 0.0),\n",
            "   ('predict', 0.0),\n",
            "   ('problem', 0.0)]),\n",
            " (3,\n",
            "  [('report', 1.0),\n",
            "   ('modular', 0.0),\n",
            "   ('postop', 0.0),\n",
            "   ('comput', 0.0),\n",
            "   ('handbook', 0.0),\n",
            "   ('linguist', 0.0),\n",
            "   ('medicin', 0.0),\n",
            "   ('related', 0.0),\n",
            "   ('predict', 0.0),\n",
            "   ('answer', 0.0)]),\n",
            " (27,\n",
            "  [('process', 0.8),\n",
            "   ('input', 0.2),\n",
            "   ('related', 0.0),\n",
            "   ('postop', 0.0),\n",
            "   ('comput', 0.0),\n",
            "   ('handbook', 0.0),\n",
            "   ('linguist', 0.0),\n",
            "   ('medicin', 0.0),\n",
            "   ('predict', 0.0),\n",
            "   ('modular', 0.0)]),\n",
            " (73,\n",
            "  [('process', 0.875),\n",
            "   ('deep', 0.125),\n",
            "   ('pdp', 0.0),\n",
            "   ('comput', 0.0),\n",
            "   ('handbook', 0.0),\n",
            "   ('linguist', 0.0),\n",
            "   ('medicin', 0.0),\n",
            "   ('related', 0.0),\n",
            "   ('predict', 0.0),\n",
            "   ('problem', 0.0)]),\n",
            " (99,\n",
            "  [('retriev', 0.6666666666666666),\n",
            "   ('convolut', 0.3333333333333333),\n",
            "   ('modular', 0.0),\n",
            "   ('comput', 0.0),\n",
            "   ('handbook', 0.0),\n",
            "   ('linguist', 0.0),\n",
            "   ('medicin', 0.0),\n",
            "   ('related', 0.0),\n",
            "   ('predict', 0.0),\n",
            "   ('record', 0.0)]),\n",
            " (53,\n",
            "  [('produc', 0.5),\n",
            "   ('requir', 0.5),\n",
            "   ('medicin', 0.0),\n",
            "   ('modular', 0.0),\n",
            "   ('thereof', 0.0),\n",
            "   ('comput', 0.0),\n",
            "   ('handbook', 0.0),\n",
            "   ('linguist', 0.0),\n",
            "   ('kind', 0.0),\n",
            "   ('record', 0.0)]),\n",
            " (98,\n",
            "  [('process', 0.6666666666666666),\n",
            "   ('mental', 0.16666666666666666),\n",
            "   ('object', 0.16666666666666666),\n",
            "   ('thereof', 0.0),\n",
            "   ('comput', 0.0),\n",
            "   ('handbook', 0.0),\n",
            "   ('linguist', 0.0),\n",
            "   ('medicin', 0.0),\n",
            "   ('predict', 0.0),\n",
            "   ('record', 0.0)]),\n",
            " (0,\n",
            "  [('semant', 0.3333333333333333),\n",
            "   ('review', 0.3333333333333333),\n",
            "   ('inform', 0.16666666666666666),\n",
            "   ('represent', 0.16666666666666666),\n",
            "   ('handbook', 0.0),\n",
            "   ('linguist', 0.0),\n",
            "   ('medicin', 0.0),\n",
            "   ('related', 0.0),\n",
            "   ('modular', 0.0),\n",
            "   ('postop', 0.0)]),\n",
            " (91,\n",
            "  [('term', 0.5),\n",
            "   ('comparison', 0.5),\n",
            "   ('medicin', 0.0),\n",
            "   ('modular', 0.0),\n",
            "   ('thereof', 0.0),\n",
            "   ('comput', 0.0),\n",
            "   ('handbook', 0.0),\n",
            "   ('linguist', 0.0),\n",
            "   ('kind', 0.0),\n",
            "   ('related', 0.0)]),\n",
            " (49,\n",
            "  [('featur', 1.0),\n",
            "   ('medicin', 0.0),\n",
            "   ('modular', 0.0),\n",
            "   ('thereof', 0.0),\n",
            "   ('comput', 0.0),\n",
            "   ('handbook', 0.0),\n",
            "   ('linguist', 0.0),\n",
            "   ('kind', 0.0),\n",
            "   ('related', 0.0),\n",
            "   ('record', 0.0)])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/wrappers/ldamallet.py:373: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return topics / topics.sum(axis=1)[:, None]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Coherence Score:  0.710532092538672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dqT5djTDm90"
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO3pDifbVk-Z",
        "outputId": "f7d564a6-e339-4a14-9130-f28f29dbe73b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized_bigrams, start=2, limit=100, step=6)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/wrappers/ldamallet.py:373: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return topics / topics.sum(axis=1)[:, None]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAgpsBNSVlBz",
        "outputId": "a6d60757-7c4b-45b5-b952-6952665395dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# Show graph\n",
        "limit=100; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwQJkdJfV4PA",
        "outputId": "13f26ce9-6ef5-4fd8-a2a8-b9684d666d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num Topics = 2  has Coherence Value of 0.6946\n",
            "Num Topics = 8  has Coherence Value of 0.7547\n",
            "Num Topics = 14  has Coherence Value of 0.7515\n",
            "Num Topics = 20  has Coherence Value of 0.7381\n",
            "Num Topics = 26  has Coherence Value of 0.7316\n",
            "Num Topics = 32  has Coherence Value of 0.7351\n",
            "Num Topics = 38  has Coherence Value of 0.7316\n",
            "Num Topics = 44  has Coherence Value of 0.7245\n",
            "Num Topics = 50  has Coherence Value of 0.7243\n",
            "Num Topics = 56  has Coherence Value of 0.7175\n",
            "Num Topics = 62  has Coherence Value of 0.7178\n",
            "Num Topics = 68  has Coherence Value of 0.7119\n",
            "Num Topics = 74  has Coherence Value of 0.7148\n",
            "Num Topics = 80  has Coherence Value of 0.7167\n",
            "Num Topics = 86  has Coherence Value of 0.715\n",
            "Num Topics = 92  has Coherence Value of 0.7162\n",
            "Num Topics = 98  has Coherence Value of 0.7146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDAUKPHFWICs",
        "outputId": "9766e814-1703-489f-f060-227fc09113c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Select the model and print the topics\n",
        "optimal_model = model_list[3]\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.364*\"neural\" + 0.091*\"account\" + 0.091*\"input\" + 0.091*\"rank\" + '\n",
            "  '0.091*\"weather\" + 0.091*\"vector\" + 0.091*\"convolut\" + 0.091*\"prolog\" + '\n",
            "  '0.000*\"handbook\" + 0.000*\"linguist\"'),\n",
            " (1,\n",
            "  '0.769*\"process\" + 0.154*\"user\" + 0.077*\"case\" + 0.000*\"modular\" + '\n",
            "  '0.000*\"pdp\" + 0.000*\"handbook\" + 0.000*\"linguist\" + 0.000*\"medicin\" + '\n",
            "  '0.000*\"related\" + 0.000*\"thereof\"'),\n",
            " (2,\n",
            "  '0.353*\"method\" + 0.059*\"detect\" + 0.059*\"geni\" + 0.059*\"rescu\" + '\n",
            "  '0.059*\"structur\" + 0.059*\"overview\" + 0.059*\"requir\" + 0.059*\"analysi\" + '\n",
            "  '0.059*\"input\" + 0.059*\"paninian\"'),\n",
            " (3,\n",
            "  '0.357*\"process\" + 0.071*\"medic\" + 0.071*\"deep\" + 0.071*\"comput\" + '\n",
            "  '0.071*\"platform\" + 0.071*\"system\" + 0.071*\"predict\" + 0.071*\"drama\" + '\n",
            "  '0.071*\"mine\" + 0.071*\"situat\"'),\n",
            " (4,\n",
            "  '0.222*\"semant\" + 0.056*\"space\" + 0.056*\"radiolog\" + 0.056*\"transfer\" + '\n",
            "  '0.056*\"jump\" + 0.056*\"record\" + 0.056*\"inform\" + 0.056*\"molecular\" + '\n",
            "  '0.056*\"strategi\" + 0.056*\"maximum\"'),\n",
            " (5,\n",
            "  '0.222*\"review\" + 0.167*\"speech\" + 0.167*\"recognit\" + 0.056*\"overal\" + '\n",
            "  '0.056*\"document\" + 0.056*\"orient\" + 0.056*\"multitask\" + 0.056*\"techniqu\" + '\n",
            "  '0.056*\"corenlp\" + 0.056*\"trend\"'),\n",
            " (6,\n",
            "  '0.190*\"retriev\" + 0.143*\"inform\" + 0.095*\"medicin\" + 0.048*\"curv\" + '\n",
            "  '0.048*\"domain\" + 0.048*\"handbook\" + 0.048*\"pdp\" + 0.048*\"map\" + '\n",
            "  '0.048*\"kind\" + 0.048*\"research\"'),\n",
            " (7,\n",
            "  '0.412*\"learn\" + 0.118*\"model\" + 0.059*\"linguist\" + 0.059*\"sentenc\" + '\n",
            "  '0.059*\"interfac\" + 0.059*\"produc\" + 0.059*\"featur\" + 0.059*\"advanc\" + '\n",
            "  '0.059*\"simpl\" + 0.059*\"word\"'),\n",
            " (8,\n",
            "  '0.364*\"represent\" + 0.182*\"deep\" + 0.091*\"perspect\" + 0.091*\"appli\" + '\n",
            "  '0.091*\"clinic\" + 0.091*\"select\" + 0.091*\"charact\" + 0.000*\"handbook\" + '\n",
            "  '0.000*\"comput\" + 0.000*\"problem\"'),\n",
            " (9,\n",
            "  '0.600*\"system\" + 0.040*\"recent\" + 0.040*\"forecast\" + 0.040*\"programm\" + '\n",
            "  '0.040*\"mine\" + 0.040*\"detect\" + 0.040*\"present\" + 0.040*\"semant\" + '\n",
            "  '0.040*\"sentenc\" + 0.040*\"overview\"'),\n",
            " (10,\n",
            "  '0.615*\"process\" + 0.154*\"model\" + 0.077*\"summari\" + 0.077*\"textual\" + '\n",
            "  '0.077*\"term\" + 0.000*\"modular\" + 0.000*\"comput\" + 0.000*\"handbook\" + '\n",
            "  '0.000*\"linguist\" + 0.000*\"medicin\"'),\n",
            " (11,\n",
            "  '0.235*\"base\" + 0.235*\"text\" + 0.176*\"extract\" + 0.059*\"result\" + '\n",
            "  '0.059*\"search\" + 0.059*\"advertis\" + 0.059*\"preposit\" + 0.059*\"biome\" + '\n",
            "  '0.059*\"comparison\" + 0.000*\"thereof\"'),\n",
            " (12,\n",
            "  '0.111*\"defect\" + 0.111*\"related\" + 0.111*\"precis\" + 0.111*\"topic\" + '\n",
            "  '0.111*\"inform\" + 0.111*\"adver\" + 0.111*\"detect\" + 0.111*\"toolkit\" + '\n",
            "  '0.111*\"interpret\" + 0.000*\"linguist\"'),\n",
            " (13,\n",
            "  '0.200*\"modular\" + 0.200*\"report\" + 0.200*\"biome\" + 0.200*\"embed\" + '\n",
            "  '0.200*\"sentiment\" + 0.000*\"comput\" + 0.000*\"handbook\" + 0.000*\"linguist\" + '\n",
            "  '0.000*\"medicin\" + 0.000*\"related\"'),\n",
            " (14,\n",
            "  '0.583*\"process\" + 0.083*\"event\" + 0.083*\"introduct\" + 0.083*\"arab\" + '\n",
            "  '0.083*\"systemat\" + 0.083*\"answer\" + 0.000*\"thereof\" + 0.000*\"comput\" + '\n",
            "  '0.000*\"handbook\" + 0.000*\"predict\"'),\n",
            " (15,\n",
            "  '0.952*\"process\" + 0.048*\"postop\" + 0.000*\"medicin\" + 0.000*\"pdp\" + '\n",
            "  '0.000*\"thereof\" + 0.000*\"comput\" + 0.000*\"handbook\" + 0.000*\"linguist\" + '\n",
            "  '0.000*\"kind\" + 0.000*\"related\"'),\n",
            " (16,\n",
            "  '0.526*\"process\" + 0.263*\"network\" + 0.053*\"employ\" + 0.053*\"support\" + '\n",
            "  '0.053*\"par\" + 0.053*\"toolkit\" + 0.000*\"linguist\" + 0.000*\"medicin\" + '\n",
            "  '0.000*\"handbook\" + 0.000*\"modular\"'),\n",
            " (17,\n",
            "  '0.889*\"process\" + 0.111*\"applic\" + 0.000*\"related\" + 0.000*\"postop\" + '\n",
            "  '0.000*\"comput\" + 0.000*\"handbook\" + 0.000*\"linguist\" + 0.000*\"medicin\" + '\n",
            "  '0.000*\"predict\" + 0.000*\"modular\"'),\n",
            " (18,\n",
            "  '0.812*\"process\" + 0.062*\"decis\" + 0.062*\"object\" + 0.062*\"disfluent\" + '\n",
            "  '0.000*\"thereof\" + 0.000*\"comput\" + 0.000*\"handbook\" + 0.000*\"linguist\" + '\n",
            "  '0.000*\"medicin\" + 0.000*\"predict\"'),\n",
            " (19,\n",
            "  '0.619*\"process\" + 0.048*\"datum\" + 0.048*\"opinion\" + 0.048*\"rnn\" + '\n",
            "  '0.048*\"discharg\" + 0.048*\"mental\" + 0.048*\"thereof\" + 0.048*\"read\" + '\n",
            "  '0.048*\"approach\" + 0.000*\"handbook\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCHyvl8gMYS-"
      },
      "source": [
        "## (2) (8 points) Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UavIv0qzMYS_"
      },
      "source": [
        "# Write your code here\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6A-dDliMYTF"
      },
      "source": [
        "## (3) (4 points) Compare the results generated by the two topic modeling algorithms, which one is better? You should explain the reasons in details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUPgyvyOMYTG"
      },
      "source": [
        "# Write your answer here (no code needed for this question)"
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}