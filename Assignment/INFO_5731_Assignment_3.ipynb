{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO_5731_Assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/Assignments/INFO5731_Assignment_Three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Three**\n",
        "\n",
        "In this assignment, you are required to conduct information extraction, semantic analysis based on **the dataset you collected from assignment two**. You may use scipy and numpy package in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adEmybUfE7j0",
        "outputId": "4376fe80-9be8-4d46-e6bb-4fe3659dbb42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%tensorflow_version 1.8\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z92HTMx6FAZ0",
        "outputId": "878eea7a-c132-4c69-eca5-7507d27f2346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "name = [ ]\n",
        "name_List = [ ]\n",
        "abstract = [ ]\n",
        "abstract_List=[ ]\n",
        "page_number = [0,10,20,30,40,50,60,70,80,90]\n",
        "for i in page_number:\n",
        " page = requests.get('https://citeseerx.ist.psu.edu/search;jsessionid=87FF6C66EA09F22314C131669600CF98?q=natural+language+processing&t=doc&sort=rlv&start='+ str (i), verify=False)\n",
        " soup = BeautifulSoup(page.content,'html.parser')\n",
        " name.append(soup.find_all('a',class_='remove doc_details'))\n",
        " abstract.append(soup.find_all('div',class_='pubabstract'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azkrd8aTFJof"
      },
      "source": [
        "for j in name:\n",
        "  for k in range(len(j)):\n",
        "    name_List.append(j[k].get_text())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ViThIXjFKfN"
      },
      "source": [
        "for l in abstract:\n",
        "  for m in range(len(l)):\n",
        "    abstract_List.append(l[m].get_text())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR2kXvaqFOBX"
      },
      "source": [
        "df = pd.DataFrame({'Article':name_List,'Abstract': abstract_List})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ7yJDXsFQrj",
        "outputId": "e14b9a39-832b-41ec-b467-faee88209e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n                  Foundations of statistical...</td>\n",
              "      <td>\\n                    Abstract not found\\n    ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n                  A Maximum Entropy approach...</td>\n",
              "      <td>\\n                     describe a method for s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "      <td>\\n                    Scaling conditional rand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n                  Linguistics and Natural La...</td>\n",
              "      <td>\\n                    The paper addresses the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "      <td>\\n                    In most natural language...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Article                                           Abstract\n",
              "0  \\n                  Foundations of statistical...  \\n                    Abstract not found\\n    ...\n",
              "1  \\n                  A Maximum Entropy approach...  \\n                     describe a method for s...\n",
              "2                    \\nNatural Language Processing\\n  \\n                    Scaling conditional rand...\n",
              "3  \\n                  Linguistics and Natural La...  \\n                    The paper addresses the ...\n",
              "4                    \\nNatural Language Processing\\n  \\n                    In most natural language..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujQu_GTSFTC2",
        "outputId": "c25a743c-36a2-43ae-cf8c-79a0fc411b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#1 Noise removal\n",
        "df['Article'] = df['Article'].replace('\\n','',regex = True)\n",
        "df['Abstract'] = df['Abstract'].replace('\\n','',regex = True)\n",
        "df['Article'] = df['Article'].replace('[^\\w\\s]','',regex = True)\n",
        "df['Abstract'] = df['Abstract'].replace('[^\\w\\s]','',regex = True)\n",
        "#2 Remove numbers\n",
        "df['Article'] = df['Article'].str.replace('\\d+','')\n",
        "df['Abstract'] = df['Abstract'].str.replace('\\d+','')\n",
        "#3 Remove StopWords\n",
        "stop_Words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \n",
        "              \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
        "              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\",\n",
        "              \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\",\n",
        "              \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\",\n",
        "              \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\",\n",
        "              \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\",\n",
        "              \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\",\n",
        "              \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\",\n",
        "              \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\",\n",
        "              \"about\", \"against\", \"between\", \"into\", \"through\",\n",
        "              \"during\", \"before\", \"after\", \"above\", \"below\", \"to\",\n",
        "              \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\",\n",
        "              \"under\", \"again\", \"further\", \"then\", \"once\", \"here\",\n",
        "              \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\",\n",
        "              \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\",\n",
        "              \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\",\n",
        "              \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\",\n",
        "              \"don\", \"should\", \"now\"]\n",
        "# stop = stopwords.words('english')\n",
        "df['Article'] = df['Article'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_Words))\n",
        "df['Abstract'] = df['Abstract'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_Words))\n",
        "#4 Lowercase all text\n",
        "df['Article'] = df['Article'].str.lower()\n",
        "df['Abstract'] = df['Abstract'].str.lower()\n",
        "#5 Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "df['Article'] = df['Article'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "df['Abstract']= df['Abstract'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "#6 Lemmatization\n",
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "df['Abstract']=df['Abstract'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdwacxuyHjW7",
        "outputId": "1fbec665-fdcd-46fe-c833-2e95a42d1de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>foundat statist natur languag process</td>\n",
              "      <td>abstract found</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a maximum entropi approach natur languag process</td>\n",
              "      <td>describ method statist model base maximum entr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>natur languag process</td>\n",
              "      <td>scale condit random field natur languag proces...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>linguist natur languag process</td>\n",
              "      <td>the paper address issu cooper linguist natur l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>natur languag process</td>\n",
              "      <td>in natur languag process applic descript logic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>natur languag process almost scratch</td>\n",
              "      <td>we propos unifi neural network architectur lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>natur languag process</td>\n",
              "      <td>natur languag process the subject natur langua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>natur languag processingrobot</td>\n",
              "      <td>robot interact human facetofac use natur langu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tutori natur languag process</td>\n",
              "      <td>natur languag languag spoken human current yet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ambigu natur languag process</td>\n",
              "      <td>abstract ambigu refer abil one mean understood...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Article                                           Abstract\n",
              "0             foundat statist natur languag process                                     abstract found\n",
              "1  a maximum entropi approach natur languag process  describ method statist model base maximum entr...\n",
              "2                             natur languag process  scale condit random field natur languag proces...\n",
              "3                    linguist natur languag process  the paper address issu cooper linguist natur l...\n",
              "4                             natur languag process  in natur languag process applic descript logic...\n",
              "5              natur languag process almost scratch  we propos unifi neural network architectur lea...\n",
              "6                             natur languag process  natur languag process the subject natur langua...\n",
              "7                     natur languag processingrobot  robot interact human facetofac use natur langu...\n",
              "8                      tutori natur languag process  natur languag languag spoken human current yet...\n",
              "9                      ambigu natur languag process  abstract ambigu refer abil one mean understood..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Understand N-gram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(45 points). Write a python program to conduct N-gram analysis based on the dataset in your assignment two:\n",
        "\n",
        "(1) Count the frequency of all the N-grams (N=3).\n",
        "\n",
        "(2) Calculate the probabilities for all the bigrams in the dataset by using the fomular count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33.\n",
        "\n",
        "(3) Extract all the **noun phrases** and calculate the relative probabilities of each review in terms of other reviews (abstracts, or tweets) by using the fomular frequency (noun phrase) / max frequency (noun phrase) on the whole dataset. Print out the result in a table with column name the all the noun phrases and row name as all the 100 reviews (abstracts, or tweets). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFPKhC0m1fd"
      },
      "source": [
        "# Write your code here\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6oqbJqWXlIv",
        "outputId": "f3b01006-2c31-459d-a752-2df188cf9156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvE-5JFsKeLW"
      },
      "source": [
        "df['WordToken_Abstract'] = df['Abstract'].apply(lambda x: word_tokenize(x))\n",
        "df['WordToken_Article'] = df['Article'].apply(lambda x: word_tokenize(x))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py1wjCCqxX6d",
        "outputId": "ec7d285d-8957-4c2b-9c19-9cf6769b1cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "df['TriGram_Abstract'] = df['WordToken_Abstract'].apply(lambda x: list (ngrams(x,3)))\n",
        "df['TriGram_Article'] = df['WordToken_Article'].apply(lambda x: list (ngrams(x,3)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9jWd0pXxyko",
        "outputId": "5f3f83ee-6ae9-432b-b40b-042450724a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df['TriGram_Abstract'].head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                   []\n",
              "1    [(describ, method, statist), (method, statist,...\n",
              "2    [(scale, condit, random), (condit, random, fie...\n",
              "3    [(the, paper, address), (paper, address, issu)...\n",
              "4    [(in, natur, languag), (natur, languag, proces...\n",
              "Name: TriGram_Abstract, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCL-ozg1MLI4",
        "outputId": "34879376-e097-4383-eccc-ae81e9025ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df['TriGram_Article'].head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [(foundat, statist, natur), (statist, natur, l...\n",
              "1    [(a, maximum, entropi), (maximum, entropi, app...\n",
              "2                          [(natur, languag, process)]\n",
              "3    [(linguist, natur, languag), (natur, languag, ...\n",
              "4                          [(natur, languag, process)]\n",
              "Name: TriGram_Article, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiJm7NWvTqEt"
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "article_Trigram_list = list (chain(*df['TriGram_Article']))\n",
        "abstract_Trigram_list = list (chain(*df['TriGram_Abstract']))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ybW_qJkW681",
        "outputId": "7a28e34f-5143-449b-ca8e-7cbb4045a8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(Counter(article_Trigram_list))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({('natur', 'languag', 'process'): 98, ('learn', 'natur', 'languag'): 5, ('languag', 'process', 'system'): 5, ('for', 'natur', 'languag'): 5, ('languag', 'process', 'inform'): 4, ('process', 'inform', 'retriev'): 4, ('statist', 'natur', 'languag'): 2, ('approach', 'natur', 'languag'): 2, ('languag', 'process', 'a'): 2, ('overview', 'natur', 'languag'): 2, ('evalu', 'natur', 'languag'): 2, ('languag', 'process', 'use'): 2, ('logic', 'natur', 'languag'): 2, ('model', 'natur', 'languag'): 2, ('on', 'natur', 'languag'): 2, ('languag', 'process', 'plan'): 2, ('process', 'plan', 'recognit'): 2, ('machin', 'learn', 'natur'): 2, ('languag', 'process', 'in'): 2, ('computerassist', 'languag', 'learn'): 2, ('in', 'natur', 'languag'): 2, ('foundat', 'statist', 'natur'): 1, ('a', 'maximum', 'entropi'): 1, ('maximum', 'entropi', 'approach'): 1, ('entropi', 'approach', 'natur'): 1, ('linguist', 'natur', 'languag'): 1, ('languag', 'process', 'almost'): 1, ('process', 'almost', 'scratch'): 1, ('natur', 'languag', 'processingrobot'): 1, ('tutori', 'natur', 'languag'): 1, ('ambigu', 'natur', 'languag'): 1, ('languag', 'process', 'lyric'): 1, ('transformationbas', 'errordriven', 'learn'): 1, ('errordriven', 'learn', 'natur'): 1, ('process', 'a', 'case'): 1, ('a', 'case', 'studi'): 1, ('case', 'studi', 'partofspeech'): 1, ('studi', 'partofspeech', 'tag'): 1, ('connectionist', 'natur', 'languag'): 1, ('chao', 'natur', 'languag'): 1, ('languag', 'process', 'introduct'): 1, ('analysi', 'natur', 'languag'): 1, ('process', 'use', 'nltk'): 1, ('languag', 'process', 'complex'): 1, ('process', 'complex', 'parallel'): 1, ('larg', 'lexicon', 'for'): 1, ('lexicon', 'for', 'natur'): 1, ('languag', 'process', 'structur'): 1, ('process', 'structur', 'complex'): 1, ('deep', 'learn', 'natur'): 1, ('languag', 'process', 'textual'): 1, ('process', 'textual', 'requir'): 1, ('ant', 'natur', 'languag'): 1, ('ontolog', 'natur', 'languag'): 1, ('retriev', 'natur', 'languag'): 1, ('thesaurus', 'for', 'natur'): 1, ('languag', 'process', 'section'): 1, ('languag', 'process', 'group'): 1, ('biomed', 'natur', 'languag'): 1, ('an', 'introduct', 'natur'): 1, ('introduct', 'natur', 'languag'): 1, ('integr', 'speech', 'naturallanguag'): 1, ('speech', 'naturallanguag', 'process'): 1, ('paradigm', 'merger', 'natur'): 1, ('merger', 'natur', 'languag'): 1, ('visual', 'tool', 'natur'): 1, ('tool', 'natur', 'languag'): 1, ('descript', 'logic', 'natur'): 1, ('structur', 'learn', 'for'): 1, ('learn', 'for', 'natur'): 1, ('commerci', 'applic', 'natur'): 1, ('applic', 'natur', 'languag'): 1, ('network', 'natur', 'languag'): 1, ('current', 'issu', 'softwar'): 1, ('issu', 'softwar', 'engin'): 1, ('softwar', 'engin', 'natur'): 1, ('engin', 'natur', 'languag'): 1, ('kernel', 'sort', 'natur'): 1, ('sort', 'natur', 'languag'): 1, ('distribut', 'approach', 'natur'): 1, ('decompos', 'model', 'natur'): 1, ('inform', 'retriev', 'malayalam'): 1, ('retriev', 'malayalam', 'use'): 1, ('malayalam', 'use', 'natur'): 1, ('use', 'natur', 'languag'): 1, ('induct', 'logic', 'natur'): 1, ('on', 'statist', 'method'): 1, ('statist', 'method', 'natur'): 1, ('method', 'natur', 'languag'): 1, ('process', 'in', 'computerassist'): 1, ('in', 'computerassist', 'languag'): 1, ('session', 'natur', 'languag'): 1, ('process', 'a', 'survey'): 1, ('an', 'overview', 'probabilist'): 1, ('overview', 'probabilist', 'tree'): 1, ('probabilist', 'tree', 'transduc'): 1, ('tree', 'transduc', 'natur'): 1, ('transduc', 'natur', 'languag'): 1, ('principl', 'evalu', 'natur'): 1, ('languag', 'process', 'thoughttreasur'): 1, ('a', 'broadcoverag', 'natur'): 1, ('broadcoverag', 'natur', 'languag'): 1, ('logic', 'program', 'natur'): 1, ('program', 'natur', 'languag'): 1, ('a', 'unifi', 'architectur'): 1, ('unifi', 'architectur', 'natur'): 1, ('architectur', 'natur', 'languag'): 1, ('languag', 'process', 'deep'): 1, ('process', 'deep', 'neural'): 1, ('deep', 'neural', 'network'): 1, ('neural', 'network', 'multitask'): 1, ('network', 'multitask', 'learn'): 1, ('inform', 'retriev', 'use'): 1, ('retriev', 'use', 'robust'): 1, ('use', 'robust', 'natur'): 1, ('robust', 'natur', 'languag'): 1, ('an', 'overview', 'empir'): 1, ('overview', 'empir', 'natur'): 1, ('empir', 'natur', 'languag'): 1, ('toward', 'contextadapt', 'natur'): 1, ('contextadapt', 'natur', 'languag'): 1, ('teach', 'appli', 'natur'): 1, ('appli', 'natur', 'languag'): 1, ('languag', 'process', 'triumph'): 1, ('process', 'triumph', 'tribul'): 1, ('on', 'memori', 'limit'): 1, ('memori', 'limit', 'in'): 1, ('limit', 'in', 'natur'): 1, ('languag', 'process', 'an'): 1, ('process', 'an', 'approach'): 1, ('an', 'approach', 'pars'): 1, ('approach', 'pars', 'semant'): 1, ('pars', 'semant', 'analysi'): 1, ('a', 'review', 'on'): 1, ('review', 'on', 'the'): 1, ('on', 'the', 'progress'): 1, ('the', 'progress', 'of'): 1, ('progress', 'of', 'natur'): 1, ('of', 'natur', 'languag'): 1, ('process', 'in', 'india'): 1, ('an', 'evalu', 'lolita'): 1, ('evalu', 'lolita', 'relat'): 1, ('lolita', 'relat', 'natur'): 1, ('relat', 'natur', 'languag'): 1, ('webbas', 'model', 'natur'): 1, ('languag', 'learn', 'and'): 1, ('learn', 'and', 'natur'): 1, ('and', 'natur', 'languag'): 1, ('learn', 'schemata', 'natur'): 1, ('schemata', 'natur', 'languag'): 1, ('softwar', 'infrastructur', 'natur'): 1, ('infrastructur', 'natur', 'languag'): 1, ('confid', 'estim', 'for'): 1, ('estim', 'for', 'natur'): 1, ('languag', 'process', 'applic'): 1, ('lexic', 'issu', 'natur'): 1, ('issu', 'natur', 'languag'): 1, ('the', 'stanford', 'corenlp'): 1, ('stanford', 'corenlp', 'natur'): 1, ('corenlp', 'natur', 'languag'): 1, ('languag', 'process', 'toolkit'): 1, ('gaussian', 'process', 'natur'): 1, ('process', 'natur', 'languag'): 1, ('an', 'histor', 'overview'): 1, ('histor', 'overview', 'natur'): 1, ('process', 'system', 'that'): 1, ('system', 'that', 'learn'): 1, ('upper', 'model', 'organ'): 1, ('model', 'organ', 'knowledg'): 1, ('organ', 'knowledg', 'natur'): 1, ('knowledg', 'natur', 'languag'): 1, ('selforgan', 'map', 'in'): 1, ('map', 'in', 'natur'): 1, ('a', 'workbench', 'develop'): 1, ('workbench', 'develop', 'natur'): 1, ('develop', 'natur', 'languag'): 1, ('languag', 'process', 'tool'): 1, ('process', 'use', 'educ'): 1, ('neural', 'network', 'comput'): 1, ('network', 'comput', 'natur'): 1, ('comput', 'natur', 'languag'): 1, ('text', 'statist', 'tool'): 1, ('statist', 'tool', 'box'): 1, ('tool', 'box', 'for'): 1, ('box', 'for', 'natur'): 1, ('use', 'frame', 'semant'): 1, ('frame', 'semant', 'natur'): 1, ('semant', 'natur', 'languag'): 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGgDGX-iXvTP",
        "outputId": "fcd70208-7e26-4827-b1ea-7f1f9bf1acab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(Counter(abstract_Trigram_list))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({('natur', 'languag', 'process'): 72, ('languag', 'process', 'nlp'): 19, ('languag', 'process', 'system'): 6, ('use', 'natur', 'languag'): 4, ('languag', 'process', 'the'): 3, ('natur', 'languag', 'languag'): 3, ('languag', 'process', 'we'): 3, ('languag', 'process', 'techniqu'): 3, ('word', 'sen', 'disambigu'): 3, ('process', 'nlp', 'task'): 3, ('applic', 'natur', 'languag'): 3, ('relat', 'natur', 'languag'): 3, ('lexsign', 'senseid', 'senseid'): 3, ('in', 'natur', 'languag'): 2, ('languag', 'process', 'applic'): 2, ('neural', 'network', 'architectur'): 2, ('languag', 'process', 'task'): 2, ('partofspeech', 'tag', 'chunk'): 2, ('tag', 'chunk', 'name'): 2, ('chunk', 'name', 'entiti'): 2, ('languag', 'languag', 'spoken'): 2, ('statist', 'natur', 'languag'): 2, ('inform', 'retriev', 'system'): 2, ('in', 'paper', 'describ'): 2, ('process', 'nlp', 'techniqu'): 2, ('abstract', 'natur', 'languag'): 2, ('thi', 'paper', 'review'): 2, ('process', 'system', 'the'): 2, ('recent', 'develop', 'natur'): 2, ('develop', 'natur', 'languag'): 2, ('abstractnatur', 'languag', 'process'): 2, ('machin', 'learn', 'techniqu'): 2, ('machin', 'learn', 'ml'): 2, ('retriev', 'relev', 'document'): 2, ('par', 'word', 'sen'): 2, ('state', 'art', 'plan'): 2, ('art', 'plan', 'recognit'): 2, ('plan', 'recognit', 'system'): 2, ('recognit', 'system', 'thi'): 2, ('system', 'thi', 'paper'): 2, ('thi', 'paper', 'outlin'): 2, ('paper', 'outlin', 'relat'): 2, ('outlin', 'relat', 'natur'): 2, ('natur', 'languag', 'processingnlp'): 2, ('languag', 'processingnlp', 'plan'): 2, ('processingnlp', 'plan', 'recognitionpr'): 2, ('plan', 'recognitionpr', 'argu'): 2, ('recognitionpr', 'argu', 'effect'): 2, ('argu', 'effect', 'inform'): 2, ('effect', 'inform', 'focu'): 2, ('inform', 'focu', 'key'): 2, ('focu', 'key', 'recent'): 2, ('key', 'recent', 'research'): 2, ('recent', 'research', 'result'): 2, ('research', 'result', 'nlp'): 2, ('result', 'nlp', 'argu'): 2, ('nlp', 'argu', 'applic'): 2, ('argu', 'applic', 'pr'): 2, ('languag', 'process', 'logic'): 2, ('process', 'logic', 'program'): 2, ('thi', 'chapter', 'examin'): 2, ('chapter', 'examin', 'applic'): 2, ('examin', 'applic', 'natur'): 2, ('languag', 'process', 'computerassist'): 2, ('process', 'computerassist', 'languag'): 2, ('computerassist', 'languag', 'learn'): 2, ('languag', 'learn', 'includ'): 2, ('learn', 'includ', 'histori'): 2, ('includ', 'histori', 'work'): 2, ('histori', 'work', 'field'): 2, ('work', 'field', 'last'): 2, ('field', 'last', 'thirtyf'): 2, ('last', 'thirtyf', 'year'): 2, ('thirtyf', 'year', 'focu'): 2, ('year', 'focu', 'current'): 2, ('focu', 'current', 'develop'): 2, ('current', 'develop', 'opportun'): 2, ('applic', 'confid', 'estim'): 2, ('thi', 'paper', 'present'): 2, ('describ', 'method', 'statist'): 1, ('method', 'statist', 'model'): 1, ('statist', 'model', 'base'): 1, ('model', 'base', 'maximum'): 1, ('base', 'maximum', 'entropi'): 1, ('maximum', 'entropi', 'we'): 1, ('entropi', 'we', 'present'): 1, ('we', 'present', 'maximumlikelihood'): 1, ('present', 'maximumlikelihood', 'approach'): 1, ('maximumlikelihood', 'approach', 'automat'): 1, ('approach', 'automat', 'construct'): 1, ('automat', 'construct', 'maximum'): 1, ('construct', 'maximum', 'entropi'): 1, ('maximum', 'entropi', 'model'): 1, ('entropi', 'model', 'describ'): 1, ('model', 'describ', 'implement'): 1, ('describ', 'implement', 'approach'): 1, ('implement', 'approach', 'effici'): 1, ('approach', 'effici', 'use'): 1, ('effici', 'use', 'exampl'): 1, ('use', 'exampl', 'sever'): 1, ('exampl', 'sever', 'problem'): 1, ('sever', 'problem', 'natur'): 1, ('problem', 'natur', 'languag'): 1, ('scale', 'condit', 'random'): 1, ('condit', 'random', 'field'): 1, ('random', 'field', 'natur'): 1, ('field', 'natur', 'languag'): 1, ('languag', 'process', 'term'): 1, ('process', 'term', 'condit'): 1, ('term', 'condit', 'term'): 1, ('condit', 'term', 'condit'): 1, ('term', 'condit', 'copyright'): 1, ('condit', 'copyright', 'work'): 1, ('copyright', 'work', 'deposit'): 1, ('work', 'deposit', 'minerva'): 1, ('deposit', 'minerva', 'access'): 1, ('minerva', 'access', 'retain'): 1, ('the', 'paper', 'address'): 1, ('paper', 'address', 'issu'): 1, ('address', 'issu', 'cooper'): 1, ('issu', 'cooper', 'linguist'): 1, ('cooper', 'linguist', 'natur'): 1, ('linguist', 'natur', 'languag'): 1, ('process', 'nlp', 'gener'): 1, ('nlp', 'gener', 'linguist'): 1, ('gener', 'linguist', 'machin'): 1, ('linguist', 'machin', 'translat'): 1, ('machin', 'translat', 'mt'): 1, ('translat', 'mt', 'particular'): 1, ('mt', 'particular', 'it'): 1, ('particular', 'it', 'focus'): 1, ('it', 'focus', 'one'): 1, ('focus', 'one', 'direct'): 1, ('one', 'direct', 'cooper'): 1, ('direct', 'cooper', 'name'): 1, ('cooper', 'name', 'applic'): 1, ('name', 'applic', 'linguist'): 1, ('applic', 'linguist', 'nlp'): 1, ('linguist', 'nlp', 'virtual'): 1, ('process', 'applic', 'descript'): 1, ('applic', 'descript', 'logic'): 1, ('descript', 'logic', 'use'): 1, ('logic', 'use', 'encod'): 1, ('use', 'encod', 'knowledg'): 1, ('encod', 'knowledg', 'base'): 1, ('knowledg', 'base', 'syntact'): 1, ('base', 'syntact', 'semant'): 1, ('syntact', 'semant', 'pragmat'): 1, ('semant', 'pragmat', 'element'): 1, ('pragmat', 'element', 'need'): 1, ('element', 'need', 'drive'): 1, ('need', 'drive', 'semant'): 1, ('drive', 'semant', 'interpret'): 1, ('semant', 'interpret', 'natur'): 1, ('interpret', 'natur', 'languag'): 1, ('natur', 'languag', 'gener'): 1, ('languag', 'gener', 'process'): 1, ('gener', 'process', 'more'): 1, ('process', 'more', 'recent'): 1, ('more', 'recent', 'descript'): 1, ('recent', 'descript', 'logic'): 1, ('we', 'propos', 'unifi'): 1, ('propos', 'unifi', 'neural'): 1, ('unifi', 'neural', 'network'): 1, ('network', 'architectur', 'learn'): 1, ('architectur', 'learn', 'algorithm'): 1, ('learn', 'algorithm', 'appli'): 1, ('algorithm', 'appli', 'variou'): 1, ('appli', 'variou', 'natur'): 1, ('variou', 'natur', 'languag'): 1, ('process', 'task', 'includ'): 1, ('task', 'includ', 'partofspeech'): 1, ('includ', 'partofspeech', 'tag'): 1, ('name', 'entiti', 'recognit'): 1, ('entiti', 'recognit', 'semant'): 1, ('recognit', 'semant', 'role'): 1, ('semant', 'role', 'label'): 1, ('role', 'label', 'thi'): 1, ('label', 'thi', 'versatil'): 1, ('thi', 'versatil', 'achiev'): 1, ('versatil', 'achiev', 'tri'): 1, ('achiev', 'tri', 'avoid'): 1, ('tri', 'avoid', 'task'): 1, ('process', 'the', 'subject'): 1, ('the', 'subject', 'natur'): 1, ('subject', 'natur', 'languag'): 1, ('languag', 'process', 'consid'): 1, ('process', 'consid', 'broad'): 1, ('consid', 'broad', 'narrow'): 1, ('broad', 'narrow', 'sen'): 1, ('narrow', 'sen', 'in'): 1, ('sen', 'in', 'broad'): 1, ('in', 'broad', 'sen'): 1, ('broad', 'sen', 'cover'): 1, ('sen', 'cover', 'process'): 1, ('cover', 'process', 'issu'): 1, ('process', 'issu', 'level'): 1, ('issu', 'level', 'natur'): 1, ('level', 'natur', 'languag'): 1, ('natur', 'languag', 'understand'): 1, ('languag', 'understand', 'includ'): 1, ('understand', 'includ', 'speech'): 1, ('includ', 'speech', 'recognit'): 1, ('speech', 'recognit', 'syntact'): 1, ('recognit', 'syntact', 'semant'): 1, ('syntact', 'semant', 'analysi'): 1, ('semant', 'analysi', 'sentenc'): 1, ('robot', 'interact', 'human'): 1, ('interact', 'human', 'facetofac'): 1, ('human', 'facetofac', 'use'): 1, ('facetofac', 'use', 'natur'): 1, ('natur', 'languag', 'need'): 1, ('languag', 'need', 'respons'): 1, ('need', 'respons', 'way'): 1, ('respons', 'way', 'human'): 1, ('way', 'human', 'use'): 1, ('human', 'use', 'languag'): 1, ('use', 'languag', 'situat'): 1, ('languag', 'situat', 'we'): 1, ('situat', 'we', 'propos'): 1, ('we', 'propos', 'psychologicallyinspir'): 1, ('propos', 'psychologicallyinspir', 'natur'): 1, ('psychologicallyinspir', 'natur', 'languag'): 1, ('process', 'system', 'robot'): 1, ('system', 'robot', 'perform'): 1, ('robot', 'perform', 'increment'): 1, ('perform', 'increment', 'semant'): 1, ('increment', 'semant', 'interpret'): 1, ('semant', 'interpret', 'spoken'): 1, ('interpret', 'spoken', 'utter'): 1, ('languag', 'spoken', 'human'): 1, ('spoken', 'human', 'current'): 1, ('human', 'current', 'yet'): 1, ('current', 'yet', 'point'): 1, ('yet', 'point', 'languag'): 1, ('point', 'languag', 'unprocess'): 1, ('languag', 'unprocess', 'form'): 1, ('unprocess', 'form', 'understood'): 1, ('form', 'understood', 'comput'): 1, ('understood', 'comput', 'natur'): 1, ('comput', 'natur', 'languag'): 1, ('languag', 'process', 'collect'): 1, ('process', 'collect', 'techniqu'): 1, ('collect', 'techniqu', 'employ'): 1, ('techniqu', 'employ', 'tri'): 1, ('employ', 'tri', 'accomplish'): 1, ('tri', 'accomplish', 'goal'): 1, ('accomplish', 'goal', 'the'): 1, ('goal', 'the', 'field'): 1, ('the', 'field', 'natur'): 1, ('abstract', 'ambigu', 'refer'): 1, ('ambigu', 'refer', 'abil'): 1, ('refer', 'abil', 'one'): 1, ('abil', 'one', 'mean'): 1, ('one', 'mean', 'understood'): 1, ('mean', 'understood', 'one'): 1, ('understood', 'one', 'way'): 1, ('one', 'way', 'natur'): 1, ('way', 'natur', 'languag'): 1, ('natur', 'languag', 'ambigu'): 1, ('languag', 'ambigu', 'comput'): 1, ('ambigu', 'comput', 'abl'): 1, ('comput', 'abl', 'understand'): 1, ('abl', 'understand', 'languag'): 1, ('understand', 'languag', 'way'): 1, ('languag', 'way', 'peopl'): 1, ('way', 'peopl', 'natur'): 1, ('peopl', 'natur', 'languag'): 1, ('process', 'nlp', 'concern'): 1, ('nlp', 'concern', 'develop'): 1, ('introduct', 'statist', 'natur'): 1, ('languag', 'process', 'snlp'): 1, ('process', 'snlp', 'field'): 1, ('snlp', 'field', 'lie'): 1, ('field', 'lie', 'intersect'): 1, ('lie', 'intersect', 'natur'): 1, ('intersect', 'natur', 'languag'): 1, ('languag', 'process', 'machin'): 1, ('process', 'machin', 'learn'): 1, ('machin', 'learn', 'snlp'): 1, ('learn', 'snlp', 'dier'): 1, ('snlp', 'dier', 'tradit'): 1, ('dier', 'tradit', 'natur'): 1, ('tradit', 'natur', 'languag'): 1, ('languag', 'process', 'instead'): 1, ('process', 'instead', 'linguist'): 1, ('instead', 'linguist', 'manual'): 1, ('linguist', 'manual', 'construct'): 1, ('manual', 'construct', 'model'): 1, ('construct', 'model', 'given'): 1, ('model', 'given', 'linguist'): 1, ('text', 'directli', 'rather'): 1, ('directli', 'rather', 'eg'): 1, ('rather', 'eg', 'titl'): 1, ('eg', 'titl', 'abstract'): 1, ('titl', 'abstract', 'suggest'): 1, ('abstract', 'suggest', 'appropri'): 1, ('suggest', 'appropri', 'approach'): 1, ('appropri', 'approach', 'focu'): 1, ('approach', 'focu', 'role'): 1, ('focu', 'role', 'natur'): 1, ('role', 'natur', 'languag'): 1, ('process', 'the', 'paper'): 1, ('the', 'paper', 'also'): 1, ('paper', 'also', 'comment'): 1, ('also', 'comment', 'possibl'): 1, ('comment', 'possibl', 'connect'): 1, ('possibl', 'connect', 'data'): 1, ('connect', 'data', 'knowledg'): 1, ('data', 'knowledg', 'retriev'): 1, ('knowledg', 'retriev', 'conclud'): 1, ('retriev', 'conclud', 'emphas'): 1, ('conclud', 'emphas', 'import'): 1, ('emphas', 'import', 'rigor'): 1, ('abstract', 'languag', 'way'): 1, ('languag', 'way', 'commun'): 1, ('way', 'commun', 'word'): 1, ('commun', 'word', 'languag'): 1, ('word', 'languag', 'help'): 1, ('languag', 'help', 'understand'): 1, ('help', 'understand', 'worldw'): 1, ('understand', 'worldw', 'get'): 1, ('worldw', 'get', 'better'): 1, ('get', 'better', 'insight'): 1, ('better', 'insight', 'world'): 1, ('insight', 'world', 'languag'): 1, ('world', 'languag', 'help'): 1, ('languag', 'help', 'speaker'): 1, ('help', 'speaker', 'vagu'): 1, ('speaker', 'vagu', 'precis'): 1, ('vagu', 'precis', 'like'): 1, ('precis', 'like', 'nlp'): 1, ('like', 'nlp', 'stand'): 1, ('nlp', 'stand', 'natur'): 1, ('stand', 'natur', 'languag'): 1, ('languag', 'process', 'natur'): 1, ('process', 'natur', 'languag'): 1, ('we', 'report', 'experi'): 1, ('report', 'experi', 'use'): 1, ('experi', 'use', 'standard'): 1, ('use', 'standard', 'natur'): 1, ('standard', 'natur', 'languag'): 1, ('process', 'nlp', 'tool'): 1, ('nlp', 'tool', 'analysi'): 1, ('tool', 'analysi', 'music'): 1, ('analysi', 'music', 'lyric'): 1, ('music', 'lyric', 'a'): 1, ('lyric', 'a', 'signific'): 1, ('a', 'signific', 'amount'): 1, ('signific', 'amount', 'music'): 1, ('amount', 'music', 'audio'): 1, ('music', 'audio', 'lyric'): 1, ('audio', 'lyric', 'lyric'): 1, ('lyric', 'lyric', 'encod'): 1, ('lyric', 'encod', 'import'): 1, ('encod', 'import', 'part'): 1, ('import', 'part', 'semant'): 1, ('part', 'semant', 'song'): 1, ('semant', 'song', 'therefor'): 1, ('song', 'therefor', 'analysi'): 1, ('therefor', 'analysi', 'complement'): 1, ('analysi', 'complement', 'acoust'): 1, ('complement', 'acoust', 'cultur'): 1, ('paper', 'describ', 'simpl'): 1, ('describ', 'simpl', 'rulebas'): 1, ('simpl', 'rulebas', 'approach'): 1, ('rulebas', 'approach', 'autom'): 1, ('approach', 'autom', 'learn'): 1, ('autom', 'learn', 'linguist'): 1, ('learn', 'linguist', 'knowledg'): 1, ('linguist', 'knowledg', 'thi'): 1, ('knowledg', 'thi', 'approach'): 1, ('thi', 'approach', 'shown'): 1, ('approach', 'shown', 'number'): 1, ('shown', 'number', 'task'): 1, ('number', 'task', 'captur'): 1, ('task', 'captur', 'inform'): 1, ('captur', 'inform', 'clearer'): 1, ('inform', 'clearer', 'direct'): 1, ('clearer', 'direct', 'fashion'): 1, ('direct', 'fashion', 'without'): 1, ('fashion', 'without', 'compromis'): 1, ('without', 'compromis', 'perform'): 1, ('compromis', 'perform', 'we'): 1, ('perform', 'we', 'present'): 1, ('we', 'present', 'detail'): 1, ('present', 'detail', 'case'): 1, ('detail', 'case', 'studi'): 1, ('case', 'studi', 'learn'): 1, ('studi', 'learn', 'method'): 1, ('learn', 'method', 'appli'): 1, ('method', 'appli', 'part'): 1, ('appli', 'part', 'speech'): 1, ('part', 'speech', 'tag'): 1, ('thi', 'paper', 'focus'): 1, ('paper', 'focus', 'connectionist'): 1, ('focus', 'connectionist', 'model'): 1, ('connectionist', 'model', 'natur'): 1, ('model', 'natur', 'languag'): 1, ('process', 'we', 'briefli'): 1, ('we', 'briefli', 'present'): 1, ('briefli', 'present', 'discus'): 1, ('present', 'discus', 'sever'): 1, ('discus', 'sever', 'aspect'): 1, ('sever', 'aspect', 'high'): 1, ('aspect', 'high', 'level'): 1, ('high', 'level', 'task'): 1, ('level', 'task', 'recent'): 1, ('task', 'recent', 'approach'): 1, ('recent', 'approach', 'connection'): 1, ('approach', 'connection', 'either'): 1, ('connection', 'either', 'localist'): 1, ('either', 'localist', 'parallel'): 1, ('localist', 'parallel', 'distribut'): 1, ('parallel', 'distribut', 'process'): 1, ('distribut', 'process', 'model'): 1, ('process', 'model', 'sever'): 1, ('model', 'sever', 'interest'): 1, ('sever', 'interest', 'architectur'): 1, ('process', 'languag', 'understand'): 1, ('languag', 'understand', 'thi'): 1, ('understand', 'thi', 'new'): 1, ('thi', 'new', 'approach'): 1, ('new', 'approach', 'natur'): 1, ('approach', 'natur', 'languag'): 1, ('languag', 'process', 'base'): 1, ('process', 'base', 'determinist'): 1, ('base', 'determinist', 'chaotic'): 1, ('determinist', 'chaotic', 'behavior'): 1, ('chaotic', 'behavior', 'dynam'): 1, ('behavior', 'dynam', 'system'): 1, ('paper', 'see', 'schank'): 1, ('see', 'schank', 'theoret'): 1, ('schank', 'theoret', 'discus'): 1, ('theoret', 'discus', 'ka'): 1, ('discus', 'ka', 'leak'): 1, ('ka', 'leak', 'owen'): 1, ('leak', 'owen', 'brief'): 1, ('owen', 'brief', 'discus'): 1, ('brief', 'discus', 'program'): 1, ('discus', 'program', 'built'): 1, ('program', 'built', 'around'): 1, ('built', 'around', 'principl'): 1, ('around', 'principl', 'goal'): 1, ('principl', 'goal', 'simpli'): 1, ('goal', 'simpli', 'point'): 1, ('simpli', 'point', 'interest'): 1, ('point', 'interest', 'natur'): 1, ('interest', 'natur', 'languag'): 1, ('languag', 'process', 'led'): 1, ('process', 'led', 'u'): 1, ('led', 'u', 'natur'): 1, ('u', 'natur', 'inde'): 1, ('natur', 'inde', 'inevit'): 1, ('object', 'to', 'provid'): 1, ('to', 'provid', 'overview'): 1, ('provid', 'overview', 'tutori'): 1, ('overview', 'tutori', 'natur'): 1, ('tutori', 'natur', 'languag'): 1, ('process', 'nlp', 'modern'): 1, ('nlp', 'modern', 'nlpsystem'): 1, ('modern', 'nlpsystem', 'design'): 1, ('nlpsystem', 'design', 'target'): 1, ('design', 'target', 'audienc'): 1, ('target', 'audienc', 'thi'): 1, ('audienc', 'thi', 'tutori'): 1, ('thi', 'tutori', 'target'): 1, ('tutori', 'target', 'medic'): 1, ('target', 'medic', 'informat'): 1, ('medic', 'informat', 'generalist'): 1, ('informat', 'generalist', 'limit'): 1, ('generalist', 'limit', 'acquaint'): 1, ('limit', 'acquaint', 'principl'): 1, ('acquaint', 'principl', 'behind'): 1, ('principl', 'behind', 'nlp'): 1, ('behind', 'nlp', 'andor'): 1, ('nlp', 'andor', 'limit'): 1, ('andor', 'limit', 'knowledg'): 1, ('limit', 'knowledg', 'current'): 1, ('knowledg', 'current', 'state'): 1, ('thi', 'paper', 'briefli'): 1, ('paper', 'briefli', 'describ'): 1, ('briefli', 'describ', 'current'): 1, ('describ', 'current', 'implement'): 1, ('current', 'implement', 'statu'): 1, ('implement', 'statu', 'intellig'): 1, ('statu', 'intellig', 'inform'): 1, ('intellig', 'inform', 'retriev'): 1, ('retriev', 'system', 'mari'): 1, ('system', 'mari', 'employ'): 1, ('mari', 'employ', 'natur'): 1, ('employ', 'natur', 'languag'): 1, ('process', 'techniqu', 'descript'): 1, ('techniqu', 'descript', 'caption'): 1, ('descript', 'caption', 'use'): 1, ('caption', 'use', 'iden'): 1, ('use', 'iden', 'tifi'): 1, ('iden', 'tifi', 'photograph'): 1, ('tifi', 'photograph', 'imag'): 1, ('photograph', 'imag', 'concern'): 1, ('imag', 'concern', 'variou'): 1, ('concern', 'variou', 'militari'): 1, ('variou', 'militari', 'project'): 1, ('militari', 'project', 'the'): 1, ('project', 'the', 'caption'): 1, ('the', 'caption', 'par'): 1, ('base', 'literatur', 'resourc'): 1, ('literatur', 'resourc', 'we'): 1, ('resourc', 'we', 'describ'): 1, ('we', 'describ', 'system'): 1, ('describ', 'system', 'agent'): 1, ('system', 'agent', 'direct'): 1, ('agent', 'direct', 'natur'): 1, ('direct', 'natur', 'languag'): 1, ('languag', 'process', 'extract'): 1, ('process', 'extract', 'inform'): 1, ('extract', 'inform', 'journal'): 1, ('inform', 'journal', 'articl'): 1, ('journal', 'articl', 'an'): 1, ('articl', 'an', 'interfac'): 1, ('an', 'interfac', 'develop'): 1, ('interfac', 'develop', 'permit'): 1, ('develop', 'permit', 'curat'): 1, ('permit', 'curat', 'nlp'): 1, ('curat', 'nlp', 'result'): 1, ('nlp', 'result', 'deposit'): 1, ('result', 'deposit', 'accept'): 1, ('deposit', 'accept', 'result'): 1, ('accept', 'result', 'knowledg'): 1, ('result', 'knowledg', 'base'): 1, ('knowledg', 'base', 'motiv'): 1, ('base', 'motiv', 'the'): 1, ('motiv', 'the', 'advent'): 1, ('the', 'advent', 'high'): 1, ('evalu', 'speech', 'process'): 1, ('speech', 'process', 'part'): 1, ('process', 'part', 'survey'): 1, ('part', 'survey', 'signific'): 1, ('survey', 'signific', 'evalu'): 1, ('signific', 'evalu', 'work'): 1, ('evalu', 'work', 'done'): 1, ('work', 'done', 'far'): 1, ('done', 'far', 'instanc'): 1, ('far', 'instanc', 'machin'): 1, ('instanc', 'machin', 'translat'): 1, ('machin', 'translat', 'discus'): 1, ('translat', 'discus', 'particular'): 1, ('discus', 'particular', 'problem'): 1, ('particular', 'problem', 'gener'): 1, ('problem', 'gener', 'system'): 1, ('gener', 'system', 'evalu'): 1, ('system', 'evalu', 'the'): 1, ('evalu', 'the', 'conclus'): 1, ('the', 'conclus', 'evalu'): 1, ('conclus', 'evalu', 'strategi'): 1, ('evalu', 'strategi', 'techniqu'): 1, ('strategi', 'techniqu', 'nlp'): 1, ('techniqu', 'nlp', 'need'): 1, ('nlp', 'need', 'much'): 1, ('need', 'much', 'develop'): 1, ('much', 'develop', 'particular'): 1, ('similar', 'way', 'human'): 1, ('way', 'human', 'intuit'): 1, ('human', 'intuit', 'order'): 1, ('intuit', 'order', 'elimin'): 1, ('order', 'elimin', 'noisi'): 1, ('elimin', 'noisi', 'content'): 1, ('noisi', 'content', 'in'): 1, ('content', 'in', 'paper'): 1, ('paper', 'describ', 'combin'): 1, ('describ', 'combin', 'html'): 1, ('combin', 'html', 'dom'): 1, ('html', 'dom', 'analysi'): 1, ('dom', 'analysi', 'natur'): 1, ('analysi', 'natur', 'languag'): 1, ('nlp', 'techniqu', 'autom'): 1, ('techniqu', 'autom', 'extract'): 1, ('autom', 'extract', 'main'): 1, ('extract', 'main', 'articl'): 1, ('main', 'articl', 'associ'): 1, ('articl', 'associ', 'imag'): 1, ('associ', 'imag', 'web'): 1, ('imag', 'web', 'page'): 1, ('languag', 'process', 'theoret'): 1, ('process', 'theoret', 'motiv'): 1, ('theoret', 'motiv', 'rang'): 1, ('motiv', 'rang', 'comput'): 1, ('rang', 'comput', 'techniqu'): 1, ('comput', 'techniqu', 'analys'): 1, ('techniqu', 'analys', 'repres'): 1, ('analys', 'repres', 'natur'): 1, ('repres', 'natur', 'occur'): 1, ('natur', 'occur', 'text'): 1, ('occur', 'text', 'one'): 1, ('text', 'one', 'level'): 1, ('one', 'level', 'linguist'): 1, ('level', 'linguist', 'analysi'): 1, ('linguist', 'analysi', 'purpos'): 1, ('analysi', 'purpos', 'achiev'): 1, ('purpos', 'achiev', 'humanlik'): 1, ('achiev', 'humanlik', 'languag'): 1, ('humanlik', 'languag', 'process'): 1, ('languag', 'process', 'rang'): 1, ('process', 'rang', 'task'): 1, ('paper', 'review', 'process'): 1, ('review', 'process', 'involv'): 1, ('process', 'involv', 'natur'): 1, ('involv', 'natur', 'languag'): 1, ('process', 'nlp', 'it'): 1, ('nlp', 'it', 'demonstr'): 1, ('it', 'demonstr', 'variou'): 1, ('demonstr', 'variou', 'kind'): 1, ('variou', 'kind', 'choic'): 1, ('kind', 'choic', 'need'): 1, ('choic', 'need', 'taken'): 1, ('need', 'taken', 'execut'): 1, ('taken', 'execut', 'word'): 1, ('execut', 'word', 'morpholog'): 1, ('word', 'morpholog', 'syntact'): 1, ('morpholog', 'syntact', 'text'): 1, ('syntact', 'text', 'analysi'): 1, ('text', 'analysi', 'text'): 1, ('analysi', 'text', 'gener'): 1, ('text', 'gener', 'compon'): 1, ('gener', 'compon', 'it'): 1, ('compon', 'it', 'compar'): 1, ('it', 'compar', 'time'): 1, ('compar', 'time', 'complex'): 1, ('thi', 'articl', 'focus'): 1, ('articl', 'focus', 'deriv'): 1, ('focus', 'deriv', 'larg'): 1, ('deriv', 'larg', 'lexicon'): 1, ('larg', 'lexicon', 'natur'): 1, ('lexicon', 'natur', 'languag'): 1, ('process', 'we', 'describ'): 1, ('we', 'describ', 'develop'): 1, ('describ', 'develop', 'dictionari'): 1, ('develop', 'dictionari', 'support'): 1, ('dictionari', 'support', 'environ'): 1, ('support', 'environ', 'link'): 1, ('environ', 'link', 'restructur'): 1, ('link', 'restructur', 'version'): 1, ('restructur', 'version', 'longman'): 1, ('version', 'longman', 'dictionari'): 1, ('longman', 'dictionari', 'contemporari'): 1, ('dictionari', 'contemporari', 'english'): 1, ('contemporari', 'english', 'natur'): 1, ('english', 'natur', 'languag'): 1, ('system', 'the', 'process'): 1, ('we', 'introduc', 'method'): 1, ('introduc', 'method', 'analyz'): 1, ('method', 'analyz', 'complex'): 1, ('analyz', 'complex', 'natur'): 1, ('complex', 'natur', 'languag'): 1, ('process', 'task', 'predict'): 1, ('task', 'predict', 'difficulti'): 1, ('predict', 'difficulti', 'new'): 1, ('difficulti', 'new', 'nlp'): 1, ('new', 'nlp', 'task'): 1, ('nlp', 'task', 'our'): 1, ('task', 'our', 'complex'): 1, ('our', 'complex', 'measur'): 1, ('complex', 'measur', 'deriv'): 1, ('measur', 'deriv', 'kolmogorov'): 1, ('deriv', 'kolmogorov', 'complex'): 1, ('kolmogorov', 'complex', 'class'): 1, ('complex', 'class', 'automaton'): 1, ('class', 'automaton', 'mean'): 1, ('automaton', 'mean', 'automaton'): 1, ('mean', 'automaton', 'whose'): 1, ('automaton', 'whose', 'purpos'): 1, ('whose', 'purpos', 'extract'): 1, ('purpos', 'extract', 'relev'): 1, ('extract', 'relev', 'piec'): 1, ('sound', 'text', 'motion'): 1, ('text', 'motion', 'the'): 1, ('motion', 'the', 'techniqu'): 1, ('the', 'techniqu', 'develop'): 1, ('techniqu', 'develop', 'deep'): 1, ('develop', 'deep', 'learn'): 1, ('deep', 'learn', 'research'): 1, ('learn', 'research', 'alreadi'): 1, ('research', 'alreadi', 'impact'): 1, ('alreadi', 'impact', 'research'): 1, ('impact', 'research', 'natur'): 1, ('research', 'natur', 'languag'): 1, ('languag', 'process', 'thi'): 1, ('process', 'thi', 'paper'): 1, ('paper', 'review', 'recent'): 1, ('review', 'recent', 'research'): 1, ('recent', 'research', 'deep'): 1, ('research', 'deep', 'learn'): 1, ('deep', 'learn', 'applic'): 1, ('learn', 'applic', 'recent'): 1, ('applic', 'recent', 'develop'): 1, ('thi', 'authorproduc', 'version'): 1, ('authorproduc', 'version', 'paper'): 1, ('version', 'paper', 'publish'): 1, ('paper', 'publish', 'the'): 1, ('process', 'nlp', 'applic'): 1, ('nlp', 'applic', 'autom'): 1, ('applic', 'autom', 'par'): 1, ('autom', 'par', 'machin'): 1, ('par', 'machin', 'learn'): 1, ('learn', 'techniqu', 'analyz'): 1, ('techniqu', 'analyz', 'standard'): 1, ('analyz', 'standard', 'text'): 1, ('standard', 'text', 'applic'): 1, ('text', 'applic', 'nlp'): 1, ('applic', 'nlp', 'requir'): 1, ('nlp', 'requir', 'engin'): 1, ('requir', 'engin', 'includ'): 1, ('engin', 'includ', 'extract'): 1, ('includ', 'extract', 'ontolog'): 1, ('extract', 'ontolog', 'requir'): 1, ('ontolog', 'requir', 'specif'): 1, ('requir', 'specif', 'use'): 1, ('specif', 'use', 'nlp'): 1, ('use', 'nlp', 'verifi'): 1, ('nlp', 'verifi', 'consist'): 1, ('statist', 'baselin', 'includ'): 1, ('baselin', 'includ', 'forgiv'): 1, ('includ', 'forgiv', 'natur'): 1, ('forgiv', 'natur', 'broad'): 1, ('natur', 'broad', 'coverag'): 1, ('broad', 'coverag', 'typic'): 1, ('coverag', 'typic', 'retriev'): 1, ('typic', 'retriev', 'task'): 1, ('retriev', 'task', 'lack'): 1, ('task', 'lack', 'good'): 1, ('lack', 'good', 'weight'): 1, ('good', 'weight', 'scheme'): 1, ('weight', 'scheme', 'compound'): 1, ('scheme', 'compound', 'index'): 1, ('compound', 'index', 'term'): 1, ('index', 'term', 'implicit'): 1, ('term', 'implicit', 'linguist'): 1, ('implicit', 'linguist', 'process'): 1, ('linguist', 'process', 'inher'): 1, ('process', 'inher', 'statist'): 1, ('inher', 'statist', 'method'): 1, ('statist', 'method', 'natur'): 1, ('method', 'natur', 'languag'): 1, ('process', 'techniqu', 'may'): 1, ('techniqu', 'may', 'import'): 1, ('work', 'comput', 'linguist'): 1, ('comput', 'linguist', 'began'): 1, ('linguist', 'began', 'soon'): 1, ('began', 'soon', 'develop'): 1, ('soon', 'develop', 'first'): 1, ('develop', 'first', 'comput'): 1, ('first', 'comput', 'booth'): 1, ('comput', 'booth', 'brandwood'): 1, ('booth', 'brandwood', 'cleav'): 1, ('brandwood', 'cleav', 'yet'): 1, ('cleav', 'yet', 'interven'): 1, ('yet', 'interven', 'four'): 1, ('interven', 'four', 'decad'): 1, ('four', 'decad', 'pervas'): 1, ('decad', 'pervas', 'feel'): 1, ('pervas', 'feel', 'progress'): 1, ('feel', 'progress', 'comput'): 1, ('progress', 'comput', 'understand'): 1, ('comput', 'understand', 'natur'): 1, ('understand', 'natur', 'languag'): 1, ('natur', 'languag', 'commensur'): 1, ('voic', 'recognit', 'natur'): 1, ('recognit', 'natur', 'languag'): 1, ('natur', 'languag', 'tamil'): 1, ('languag', 'tamil', 'combin'): 1, ('tamil', 'combin', 'digit'): 1, ('combin', 'digit', 'mathemat'): 1, ('digit', 'mathemat', 'knowledg'): 1, ('mathemat', 'knowledg', 'use'): 1, ('knowledg', 'use', 'mfcc'): 1, ('use', 'mfcc', 'dtw'): 1, ('mfcc', 'dtw', 'extract'): 1, ('dtw', 'extract', 'match'): 1, ('extract', 'match', 'featur'): 1, ('match', 'featur', 'improv'): 1, ('featur', 'improv', 'accuraci'): 1, ('improv', 'accuraci', 'better'): 1, ('accuraci', 'better', 'perform'): 1, ('abstract', 'test', 'natur'): 1, ('test', 'natur', 'languag'): 1, ('natur', 'languag', 'requir'): 1, ('languag', 'requir', 'standard'): 1, ('requir', 'standard', 'approach'): 1, ('standard', 'approach', 'system'): 1, ('approach', 'system', 'accept'): 1, ('system', 'accept', 'test'): 1, ('accept', 'test', 'thi'): 1, ('test', 'thi', 'test'): 1, ('thi', 'test', 'often'): 1, ('test', 'often', 'perform'): 1, ('often', 'perform', 'independ'): 1, ('perform', 'independ', 'test'): 1, ('independ', 'test', 'organ'): 1, ('test', 'organ', 'unfamiliar'): 1, ('organ', 'unfamiliar', 'applic'): 1, ('unfamiliar', 'applic', 'area'): 1, ('applic', 'area', 'the'): 1, ('area', 'the', 'thing'): 1, ('the', 'thing', 'tester'): 1, ('thing', 'tester', 'go'): 1, ('tester', 'go', 'written'): 1, ('go', 'written', 'requir'): 1, ('written', 'requir', 'so'): 1, ('convers', 'partner', 'but'): 1, ('partner', 'but', 'also'): 1, ('but', 'also', 'provid'): 1, ('also', 'provid', 'u'): 1, ('provid', 'u', 'inform'): 1, ('u', 'inform', 'creativ'): 1, ('inform', 'creativ', 'make'): 1, ('creativ', 'make', 'associ'): 1, ('make', 'associ', 'storytel'): 1, ('associ', 'storytel', 'languag'): 1, ('storytel', 'languag', 'use'): 1, ('languag', 'use', 'mani'): 1, ('use', 'mani', 'subtleti'): 1, ('mani', 'subtleti', 'facetofac'): 1, ('subtleti', 'facetofac', 'multiparti'): 1, ('facetofac', 'multiparti', 'interact'): 1, ('multiparti', 'interact', 'ad'): 1, ('interact', 'ad', 'use'): 1, ('ad', 'use', 'humor'): 1, ('use', 'humor', 'persuad'): 1, ('humor', 'persuad', 'domin'): 1, ('persuad', 'domin', 'soften'): 1, ('domin', 'soften', 'avoid'): 1, ('soften', 'avoid', 'face'): 1, ('avoid', 'face', 'threaten'): 1, ('face', 'threaten', 'act'): 1, ('in', 'recent', 'year'): 1, ('recent', 'year', 'machin'): 1, ('year', 'machin', 'learn'): 1, ('learn', 'ml', 'use'): 1, ('ml', 'use', 'solv'): 1, ('use', 'solv', 'complex'): 1, ('solv', 'complex', 'task'): 1, ('complex', 'task', 'differ'): 1, ('task', 'differ', 'disciplin'): 1, ('differ', 'disciplin', 'rang'): 1, ('disciplin', 'rang', 'data'): 1, ('rang', 'data', 'mine'): 1, ('data', 'mine', 'inform'): 1, ('we', 'argu', 'manual'): 1, ('argu', 'manual', 'automat'): 1, ('manual', 'automat', 'thesaurus'): 1, ('automat', 'thesaurus', 'altern'): 1, ('thesaurus', 'altern', 'resourc'): 1, ('altern', 'resourc', 'nlp'): 1, ('resourc', 'nlp', 'task'): 1, ('nlp', 'task', 'thi'): 1, ('task', 'thi', 'involv'): 1, ('thi', 'involv', 'radic'): 1, ('involv', 'radic', 'step'): 1, ('radic', 'step', 'interpret'): 1, ('step', 'interpret', 'manual'): 1, ('interpret', 'manual', 'thesaurus'): 1, ('manual', 'thesaurus', 'classif'): 1, ('thesaurus', 'classif', 'word'): 1, ('classif', 'word', 'rather'): 1, ('word', 'rather', 'word'): 1, ('rather', 'word', 'sen'): 1, ('word', 'sen', 'case'): 1, ('sen', 'case', 'made'): 1, ('case', 'made', 'the'): 1, ('made', 'the', 'rang'): 1, ('the', 'rang', 'role'): 1, ('rang', 'role', 'thesaurus'): 1, ('role', 'thesaurus', 'within'): 1, ('thesaurus', 'within', 'nlp'): 1, ('within', 'nlp', 'briefli'): 1, ('nlp', 'briefli', 'present'): 1, ('briefli', 'present', 'wasp'): 1, ('present', 'wasp', 'thesauru'): 1, ('wasp', 'thesauru', 'introduc'): 1, ('thesauru', 'introduc', 'thesauru'): 1, ('introduc', 'thesauru', 'evalu'): 1, ('thesauru', 'evalu', 'becom'): 1, ('evalu', 'becom', 'urgent'): 1, ('becom', 'urgent', 'a'): 1, ('urgent', 'a', 'rang'): 1, ('a', 'rang', 'evalu'): 1, ('rang', 'evalu', 'strategi'): 1, ('evalu', 'strategi', 'embed'): 1, ('strategi', 'embed', 'within'): 1, ('embed', 'within', 'nlp'): 1, ('within', 'nlp', 'task'): 1, ('nlp', 'task', 'propos'): 1, ('introduct', 'pattern', 'music'): 1, ('pattern', 'music', 'object'): 1, ('music', 'object', 'intens'): 1, ('object', 'intens', 'studi'): 1, ('intens', 'studi', 'past'): 1, ('studi', 'past', 'year'): 1, ('past', 'year', 'one'): 1, ('year', 'one', 'purpos'): 1, ('one', 'purpos', 'analyz'): 1, ('purpos', 'analyz', 'music'): 1, ('analyz', 'music', 'structur'): 1, ('music', 'structur', 'form'): 1, ('structur', 'form', 'discov'): 1, ('form', 'discov', 'pattern'): 1, ('discov', 'pattern', 'explicit'): 1, ('pattern', 'explicit', 'implicit'): 1, ('explicit', 'implicit', 'music'): 1, ('implicit', 'music', 'work'): 1, ('music', 'work', 'simon'): 1, ('work', 'simon', 'pattern'): 1, ('simon', 'pattern', 'compris'): 1, ('pattern', 'compris', 'period'): 1, ('compris', 'period', 'make'): 1, ('period', 'make', 'use'): 1, ('make', 'use', 'alphabet'): 1, ('use', 'alphabet', 'compound'): 1, ('alphabet', 'compound', 'made'): 1, ('compound', 'made', 'subpattern'): 1, ('made', 'subpattern', 'posse'): 1, ('subpattern', 'posse', 'phrase'): 1, ('posse', 'phrase', 'structur'): 1, ('phrase', 'structur', 'variou'): 1, ('structur', 'variou', 'form'): 1, ('variou', 'form', 'punctuat'): 1, ('form', 'punctuat', 'tradit'): 1, ('punctuat', 'tradit', 'compos'): 1, ('tradit', 'compos', 'employ'): 1, ('compos', 'employ', 'pattern'): 1, ('employ', 'pattern', 'propag'): 1, ('pattern', 'propag', 'intuit'): 1, ('propag', 'intuit', 'algorithm'): 1, ('intuit', 'algorithm', 'composit'): 1, ('algorithm', 'composit', 'techniqu'): 1, ('composit', 'techniqu', 'allow'): 1, ('techniqu', 'allow', 'pattern'): 1, ('allow', 'pattern', 'propag'): 1, ('pattern', 'propag', 'formal'): 1, ('propag', 'formal', 'albeit'): 1, ('formal', 'albeit', 'high'): 1, ('albeit', 'high', 'level'): 1, ('high', 'level', 'dure'): 1, ('level', 'dure', 'composit'): 1, ('dure', 'composit', 'music'): 1, ('composit', 'music', 'pattern'): 1, ('music', 'pattern', 'evolv'): 1, ('pattern', 'evolv', 'accord'): 1, ('evolv', 'accord', 'rule'): 1, ('accord', 'rule', 'constraint'): 1, ('rule', 'constraint', 'speci'): 1, ('constraint', 'speci', 'design'): 1, ('speci', 'design', 'stage'): 1, ('design', 'stage', 'in'): 1, ('stage', 'in', 'jazz'): 1, ('in', 'jazz', 'improvis'): 1, ('jazz', 'improvis', 'musician'): 1, ('improvis', 'musician', 'invent'): 1, ('musician', 'invent', 'solo'): 1, ('invent', 'solo', 'guid'): 1, ('solo', 'guid', 'progress'): 1, ('guid', 'progress', 'chord'): 1, ('progress', 'chord', 'chang'): 1, ('chord', 'chang', 'one'): 1, ('chang', 'one', 'approach'): 1, ('one', 'approach', 'learn'): 1, ('approach', 'learn', 'improvis'): 1, ('learn', 'improvis', 'memor'): 1, ('improvis', 'memor', 'pattern'): 1, ('memor', 'pattern', 'short'): 1, ('pattern', 'short', 'chunk'): 1, ('short', 'chunk', 'music'): 1, ('chunk', 'music', 'subprogress'): 1, ('music', 'subprogress', 'concaten'): 1, ('subprogress', 'concaten', 'form'): 1, ('concaten', 'form', 'whole'): 1, ('form', 'whole', 'solo'): 1, ('whole', 'solo', 't'): 1, ('solo', 't', 'whole'): 1, ('t', 'whole', 'progress'): 1, ('whole', 'progress', 'one'): 1, ('abstract', 'mani', 'inform'): 1, ('mani', 'inform', 'retrievalir'): 1, ('inform', 'retrievalir', 'system'): 1, ('retrievalir', 'system', 'retriev'): 1, ('system', 'retriev', 'relev'): 1, ('relev', 'document', 'base'): 1, ('document', 'base', 'exact'): 1, ('base', 'exact', 'match'): 1, ('exact', 'match', 'keyword'): 1, ('match', 'keyword', 'queri'): 1, ('keyword', 'queri', 'document'): 1, ('queri', 'document', 'thi'): 1, ('document', 'thi', 'method'): 1, ('thi', 'method', 'degrad'): 1, ('method', 'degrad', 'precis'): 1, ('degrad', 'precis', 'rate'): 1, ('precis', 'rate', 'in'): 1, ('rate', 'in', 'order'): 1, ('in', 'order', 'solv'): 1, ('order', 'solv', 'problem'): 1, ('solv', 'problem', 'collect'): 1, ('problem', 'collect', 'semant'): 1, ('collect', 'semant', 'relat'): 1, ('semant', 'relat', 'word'): 1, ('relat', 'word', 'assign'): 1, ('word', 'assign', 'semant'): 1, ('assign', 'semant', 'relationship'): 1, ('semant', 'relationship', 'use'): 1, ('relationship', 'use', 'gener'): 1, ('use', 'gener', 'thesauru'): 1, ('gener', 'thesauru', 'special'): 1, ('thesauru', 'special', 'relationship'): 1, ('special', 'relationship', 'call'): 1, ('relationship', 'call', 'keyfact'): 1, ('call', 'keyfact', 'termft'): 1, ('keyfact', 'termft', 'manual'): 1, ('termft', 'manual', 'in'): 1, ('manual', 'in', 'addit'): 1, ('in', 'addit', 'semant'): 1, ('addit', 'semant', 'knowledg'): 1, ('semant', 'knowledg', 'automat'): 1, ('knowledg', 'automat', 'construct'): 1, ('automat', 'construct', 'statist'): 1, ('construct', 'statist', 'knowledg'): 1, ('statist', 'knowledg', 'base'): 1, ('knowledg', 'base', 'concept'): 1, ('base', 'concept', 'mutual'): 1, ('concept', 'mutual', 'inform'): 1, ('mutual', 'inform', 'keyfact'): 1, ('inform', 'keyfact', 'extend'): 1, ('keyfact', 'extend', 'concept'): 1, ('extend', 'concept', 'keyword'): 1, ('concept', 'keyword', 'repres'): 1, ('keyword', 'repres', 'noun'): 1, ('repres', 'noun', 'compound'): 1, ('noun', 'compound', 'noun'): 1, ('compound', 'noun', 'keyfact'): 1, ('noun', 'keyfact', 'verb'): 1, ('keyfact', 'verb', 'adject'): 1, ('verb', 'adject', 'includ'): 1, ('adject', 'includ', 'subject'): 1, ('includ', 'subject', 'object'): 1, ('subject', 'object', 'term'): 1, ('object', 'term', 'we'): 1, ('term', 'we', 'first'): 1, ('we', 'first', 'retriev'): 1, ('first', 'retriev', 'relev'): 1, ('relev', 'document', 'origin'): 1, ('document', 'origin', 'queri'): 1, ('origin', 'queri', 'use'): 1, ('queri', 'use', 'tf'): 1, ('use', 'tf', 'idf'): 1, ('tf', 'idf', 'weight'): 1, ('idf', 'weight', 'formula'): 1, ('weight', 'formula', 'expand'): 1, ('formula', 'expand', 'queri'): 1, ('expand', 'queri', 'includ'): 1, ('queri', 'includ', 'keyfact'): 1, ('includ', 'keyfact', 'use'): 1, ('keyfact', 'use', 'second'): 1, ('use', 'second', 'document'): 1, ('second', 'document', 'rank'): 1, ('document', 'rank', 'word'): 1, ('rank', 'word', 'sen'): 1, ('sen', 'disambigu', 'so'): 1, ('disambigu', 'so', 'made'): 1, ('so', 'made', 'improv'): 1, ('made', 'improv', 'precis'): 1, ('improv', 'precis', 'rate'): 1, ('precis', 'rate', 'use'): 1, ('rate', 'use', 'keyfact'): 1, ('use', 'keyfact', 'network'): 1, ('paper', 'argu', 'questionansw'): 1, ('argu', 'questionansw', 'qa'): 1, ('questionansw', 'qa', 'technic'): 1, ('qa', 'technic', 'domain'): 1, ('technic', 'domain', 'distinctli'): 1, ('domain', 'distinctli', 'differ'): 1, ('distinctli', 'differ', 'trecbas'): 1, ('differ', 'trecbas', 'qa'): 1, ('trecbas', 'qa', 'webbas'): 1, ('qa', 'webbas', 'qa'): 1, ('webbas', 'qa', 'can'): 1, ('qa', 'can', 'not'): 1, ('can', 'not', 'benefit'): 1, ('not', 'benefit', 'lom'): 1, ('benefit', 'lom', 'dataintens'): 1, ('lom', 'dataintens', 'approach'): 1, ('universitquotat', 'de', 'saarland'): 1, ('sri', 'develop', 'new'): 1, ('develop', 'new', 'architectur'): 1, ('new', 'architectur', 'integr'): 1, ('architectur', 'integr', 'speech'): 1, ('integr', 'speech', 'naturallanguag'): 1, ('speech', 'naturallanguag', 'process'): 1, ('naturallanguag', 'process', 'appli'): 1, ('process', 'appli', 'linguist'): 1, ('appli', 'linguist', 'constraint'): 1, ('linguist', 'constraint', 'recognit'): 1, ('constraint', 'recognit', 'increment'): 1, ('recognit', 'increment', 'expand'): 1, ('increment', 'expand', 'statetransit'): 1, ('expand', 'statetransit', 'network'): 1, ('statetransit', 'network', 'embodi'): 1, ('network', 'embodi', 'unif'): 1, ('embodi', 'unif', 'grammar'): 1, ('unif', 'grammar', 'we'): 1, ('grammar', 'we', 'compar'): 1, ('we', 'compar', 'dynamicgralnlnarnetwork'): 1, ('compar', 'dynamicgralnlnarnetwork', 'dgn'): 1, ('dynamicgralnlnarnetwork', 'dgn', 'approach'): 1, ('thi', 'chapter', 'consid'): 1, ('chapter', 'consid', 'revolut'): 1, ('consid', 'revolut', 'taken'): 1, ('revolut', 'taken', 'place'): 1, ('taken', 'place', 'natur'): 1, ('place', 'natur', 'languag'): 1, ('languag', 'process', 'research'): 1, ('process', 'research', 'last'): 1, ('research', 'last', 'five'): 1, ('last', 'five', 'year'): 1, ('five', 'year', 'it'): 1, ('year', 'it', 'begin'): 1, ('it', 'begin', 'provid'): 1, ('begin', 'provid', 'brief'): 1, ('provid', 'brief', 'guid'): 1, ('brief', 'guid', 'structur'): 1, ('guid', 'structur', 'field'): 1, ('structur', 'field', 'present'): 1, ('field', 'present', 'caricatur'): 1, ('present', 'caricatur', 'two'): 1, ('caricatur', 'two', 'compet'): 1, ('two', 'compet', 'paradigm'): 1, ('compet', 'paradigm', 'nlp'): 1, ('paradigm', 'nlp', 'research'): 1, ('nlp', 'research', 'indic'): 1, ('research', 'indic', 'reason'): 1, ('visual', 'develop', 'environ'): 1, ('develop', 'environ', 'support'): 1, ('environ', 'support', 'visual'): 1, ('support', 'visual', 'assembl'): 1, ('visual', 'assembl', 'execut'): 1, ('assembl', 'execut', 'analysi'): 1, ('execut', 'analysi', 'modular'): 1, ('analysi', 'modular', 'natur'): 1, ('modular', 'natur', 'languag'): 1, ('system', 'the', 'visual'): 1, ('the', 'visual', 'model'): 1, ('visual', 'model', 'execut'): 1, ('model', 'execut', 'data'): 1, ('execut', 'data', 'flow'): 1, ('data', 'flow', 'program'): 1, ('flow', 'program', 'graph'): 1, ('program', 'graph', 'automat'): 1, ('graph', 'automat', 'synthesis'): 1, ('automat', 'synthesis', 'data'): 1, ('synthesis', 'data', 'depend'): 1, ('data', 'depend', 'declar'): 1, ('depend', 'declar', 'languag'): 1, ('declar', 'languag', 'process'): 1, ('languag', 'process', 'modul'): 1, ('process', 'modul', 'the'): 1, ('modul', 'the', 'graph'): 1, ('in', 'chapter', 'basic'): 1, ('chapter', 'basic', 'use'): 1, ('basic', 'use', 'descript'): 1, ('use', 'descript', 'logic'): 1, ('descript', 'logic', 'natur'): 1, ('logic', 'natur', 'languag'): 1, ('languag', 'process', 'analys'): 1, ('process', 'analys', 'togeth'): 1, ('analys', 'togeth', 'littl'): 1, ('togeth', 'littl', 'bit'): 1, ('littl', 'bit', 'histori'): 1, ('bit', 'histori', 'role'): 1, ('histori', 'role', 'descript'): 1, ('role', 'descript', 'logic'): 1, ('descript', 'logic', 'current'): 1, ('logic', 'current', 'state'): 1, ('current', 'state', 'art'): 1, ('state', 'art', 'comput'): 1, ('art', 'comput', 'linguist'): 1, ('comput', 'linguist', 'point'): 1, ('linguist', 'point', 'introduct'): 1, ('point', 'introduct', 'sinc'): 1, ('introduct', 'sinc', 'earli'): 1, ('sinc', 'earli', 'day'): 1, ('we', 'appli', 'structur'): 1, ('appli', 'structur', 'learn'): 1, ('structur', 'learn', 'model'): 1, ('learn', 'model', 'maxmargin'): 1, ('model', 'maxmargin', 'structur'): 1, ('maxmargin', 'structur', 'mm'): 1, ('structur', 'mm', 'natur'): 1, ('mm', 'natur', 'languag'): 1, ('nlp', 'task', 'aim'): 1, ('task', 'aim', 'captur'): 1, ('aim', 'captur', 'latent'): 1, ('captur', 'latent', 'relationship'): 1, ('latent', 'relationship', 'within'): 1, ('relationship', 'within', 'output'): 1, ('within', 'output', 'languag'): 1, ('output', 'languag', 'domain'): 1, ('languag', 'domain', 'we'): 1, ('domain', 'we', 'formul'): 1, ('we', 'formul', 'model'): 1, ('formul', 'model', 'extens'): 1, ('model', 'extens', 'multiclass'): 1, ('extens', 'multiclass', 'support'): 1, ('multiclass', 'support', 'vector'): 1, ('support', 'vector', 'machin'): 1, ('vector', 'machin', 'svm'): 1, ('machin', 'svm', 'present'): 1, ('mation', 'infrastructur', 'digit'): 1, ('infrastructur', 'digit', 'librari'): 1, ('digit', 'librari', 'network'): 1, ('librari', 'network', 'servic'): 1, ('network', 'servic', 'digit'): 1, ('servic', 'digit', 'converg'): 1, ('digit', 'converg', 'intellig'): 1, ('converg', 'intellig', 'agent'): 1, ('intellig', 'agent', 'thi'): 1, ('agent', 'thi', 'attent'): 1, ('thi', 'attent', 'move'): 1, ('attent', 'move', 'natur'): 1, ('move', 'natur', 'languag'): 1, ('languag', 'process', 'along'): 1, ('process', 'along', 'critic'): 1, ('along', 'critic', 'path'): 1, ('critic', 'path', 'kind'): 1, ('path', 'kind', 'novel'): 1, ('kind', 'novel', 'applic'): 1, ('novel', 'applic', 'thi'): 1, ('applic', 'thi', 'articl'): 1, ('thi', 'articl', 'mention'): 1, ('articl', 'mention', 'number'): 1, ('mention', 'number', 'success'): 1, ('number', 'success', 'applic'): 1, ('success', 'applic', 'natur'): 1, ('over', 'last', 'year'): 1, ('last', 'year', 'number'): 1, ('year', 'number', 'area'): 1, ('number', 'area', 'natur'): 1, ('area', 'natur', 'languag'): 1, ('languag', 'process', 'begun'): 1, ('process', 'begun', 'appli'): 1, ('begun', 'appli', 'graphbas'): 1, ('appli', 'graphbas', 'techniqu'): 1, ('graphbas', 'techniqu', 'these'): 1, ('techniqu', 'these', 'includ'): 1, ('these', 'includ', 'among'): 1, ('includ', 'among', 'other'): 1, ('among', 'other', 'text'): 1, ('other', 'text', 'summar'): 1, ('text', 'summar', 'syntact'): 1, ('summar', 'syntact', 'par'): 1, ('syntact', 'par', 'word'): 1, ('sen', 'disambigu', 'ontolog'): 1, ('disambigu', 'ontolog', 'construct'): 1, ('ontolog', 'construct', 'sentiment'): 1, ('construct', 'sentiment', 'subject'): 1, ('sentiment', 'subject', 'analysi'): 1, ('subject', 'analysi', 'text'): 1, ('analysi', 'text', 'cluster'): 1, ('process', 'nlp', 'research'): 1, ('nlp', 'research', 'result'): 1, ('research', 'result', 'softwar'): 1, ('result', 'softwar', 'engin'): 1, ('softwar', 'engin', 'softwar'): 1, ('engin', 'softwar', 'technolog'): 1, ('softwar', 'technolog', 'often'): 1, ('technolog', 'often', 'neglect'): 1, ('kernel', 'sort', 'increas'): 1, ('sort', 'increas', 'robust'): 1, ('increas', 'robust', 'perform'): 1, ('robust', 'perform', 'sever'): 1, ('perform', 'sever', 'natur'): 1, ('sever', 'natur', 'languag'): 1, ('nlp', 'task', 'document'): 1, ('task', 'document', 'match'): 1, ('document', 'match', 'parallel'): 1, ('match', 'parallel', 'compar'): 1, ('parallel', 'compar', 'corpus'): 1, ('compar', 'corpus', 'machin'): 1, ('corpus', 'machin', 'transliter'): 1, ('machin', 'transliter', 'even'): 1, ('transliter', 'even', 'imag'): 1, ('even', 'imag', 'process'): 1, ('imag', 'process', 'empir'): 1, ('process', 'empir', 'show'): 1, ('empir', 'show', 'task'): 1, ('show', 'task', 'semisupervis'): 1, ('task', 'semisupervis', 'variant'): 1, ('semisupervis', 'variant', 'kernel'): 1, ('structur', 'in', 'word'): 1, ('in', 'word', 'statist'): 1, ('word', 'statist', 'natur'): 1, ('languag', 'process', 'need'): 1, ('process', 'need', 'sophist'): 1, ('need', 'sophist', 'statist'): 1, ('sophist', 'statist', 'model'): 1, ('statist', 'model', 'basic'): 1, ('model', 'basic', 'element'): 1, ('basic', 'element', 'word'): 1, ('element', 'word', 'phrase'): 1, ('word', 'phrase', 'combin'): 1, ('phrase', 'combin', 'structur'): 1, ('combin', 'structur', 'model'): 1, ('structur', 'model', 'syntact'): 1, ('model', 'syntact', 'par'): 1, ('syntact', 'par', 'depend'): 1, ('par', 'depend', 'analysi'): 1, ('depend', 'analysi', 'sinc'): 1, ('analysi', 'sinc', 'basic'): 1, ('sinc', 'basic', 'properti'): 1, ('basic', 'properti', 'element'): 1, ('paper', 'describ', 'framework'): 1, ('describ', 'framework', 'develop'): 1, ('framework', 'develop', 'probabilist'): 1, ('develop', 'probabilist', 'classifi'): 1, ('probabilist', 'classifi', 'natur'): 1, ('classifi', 'natur', 'languag'): 1, ('languag', 'process', 'our'): 1, ('process', 'our', 'focu'): 1, ('our', 'focu', 'formul'): 1, ('focu', 'formul', 'model'): 1, ('formul', 'model', 'captur'): 1, ('model', 'captur', 'import'): 1, ('captur', 'import', 'interdepend'): 1, ('import', 'interdepend', 'among'): 1, ('interdepend', 'among', 'featur'): 1, ('among', 'featur', 'avoid'): 1, ('featur', 'avoid', 'overfit'): 1, ('avoid', 'overfit', 'data'): 1, ('overfit', 'data', 'also'): 1, ('data', 'also', 'character'): 1, ('also', 'character', 'data'): 1, ('character', 'data', 'well'): 1, ('data', 'well', 'the'): 1, ('well', 'the', 'class'): 1, ('mani', 'natur', 'languag'): 1, ('nlp', 'techniqu', 'use'): 1, ('techniqu', 'use', 'inform'): 1, ('use', 'inform', 'retriev'): 1, ('inform', 'retriev', 'the'): 1, ('retriev', 'the', 'result'): 1, ('the', 'result', 'encourag'): 1, ('result', 'encourag', 'simpl'): 1, ('encourag', 'simpl', 'method'): 1, ('simpl', 'method', 'stopword'): 1, ('method', 'stopword', 'porterstyl'): 1, ('stopword', 'porterstyl', 'stem'): 1, ('porterstyl', 'stem', 'etc'): 1, ('stem', 'etc', 'usual'): 1, ('etc', 'usual', 'yield'): 1, ('usual', 'yield', 'signific'): 1, ('yield', 'signific', 'improv'): 1, ('signific', 'improv', 'higherlevel'): 1, ('improv', 'higherlevel', 'process'): 1, ('higherlevel', 'process', 'chunk'): 1, ('process', 'chunk', 'par'): 1, ('chunk', 'par', 'word'): 1, ('abstract', 'thi', 'paper'): 1, ('thi', 'paper', 'explain'): 1, ('paper', 'explain', 'inform'): 1, ('explain', 'inform', 'retriev'): 1, ('inform', 'retriev', 'use'): 1, ('retriev', 'use', 'natur'): 1, ('languag', 'process', 'malayalam'): 1, ('process', 'malayalam', 'languag'): 1, ('malayalam', 'languag', 'basic'): 1, ('inform', 'retriev', 'process'): 1, ('retriev', 'process', 'find'): 1, ('process', 'find', 'document'): 1, ('find', 'document', 'document'): 1, ('document', 'document', 'collect'): 1, ('document', 'collect', 'satisfi'): 1, ('collect', 'satisfi', 'inform'): 1, ('satisfi', 'inform', 'need'): 1, ('inform', 'need', 'user'): 1, ('need', 'user', 'the'): 1, ('user', 'the', 'document'): 1, ('the', 'document', 'natur'): 1, ('document', 'natur', 'languag'): 1, ('natur', 'languag', 'construct'): 1, ('languag', 'construct', 'motiv'): 1, ('construct', 'motiv', 'work'): 1, ('motiv', 'work', 'investig'): 1, ('work', 'investig', 'natur'): 1, ('investig', 'natur', 'languag'): 1, ('languag', 'process', 'use'): 1, ('process', 'use', 'improv'): 1, ('logic', 'program', 'within'): 1, ('program', 'within', 'natur'): 1, ('within', 'natur', 'languag'): 1, ('natur', 'languag', 'research'): 1, ('languag', 'research', 'machin'): 1, ('research', 'machin', 'learn'): 1, ('machin', 'learn', 'point'): 1, ('learn', 'point', 'opportun'): 1, ('point', 'opportun', 'induct'): 1, ('opportun', 'induct', 'linguist'): 1, ('induct', 'linguist', 'knowledg'): 1, ('linguist', 'knowledg', 'within'): 1, ('knowledg', 'within', 'logic'): 1, ('within', 'logic', 'program'): 1, ('logic', 'program', 'keyword'): 1, ('program', 'keyword', 'induct'): 1, ('keyword', 'induct', 'logic'): 1, ('induct', 'logic', 'program'): 1, ('logic', 'program', 'natur'): 1, ('program', 'natur', 'languag'): 1, ('logic', 'program', 'machin'): 1, ('program', 'machin', 'learn'): 1, ('machin', 'learn', 'introduct'): 1, ('learn', 'introduct', 'there'): 1, ('what', 'statist', 'method'): 1, ('statist', 'method', 'use'): 1, ('method', 'use', 'natur'): 1, ('process', 'nlp', 'in'): 1, ('nlp', 'in', 'paper'): 1, ('in', 'paper', 'start'): 1, ('paper', 'start', 'definit'): 1, ('start', 'definit', 'nlp'): 1, ('definit', 'nlp', 'concern'): 1, ('nlp', 'concern', 'design'): 1, ('concern', 'design', 'implement'): 1, ('design', 'implement', 'effect'): 1, ('implement', 'effect', 'natur'): 1, ('effect', 'natur', 'languag'): 1, ('natur', 'languag', 'input'): 1, ('languag', 'input', 'output'): 1, ('input', 'output', 'compon'): 1, ('output', 'compon', 'comput'): 1, ('compon', 'comput', 'system'): 1, ('comput', 'system', 'we'): 1, ('system', 'we', 'distinguish'): 1, ('we', 'distinguish', 'three'): 1, ('in', 'report', 'collabor'): 1, ('report', 'collabor', 'work'): 1, ('collabor', 'work', 'field'): 1, ('work', 'field', 'machin'): 1, ('field', 'machin', 'learn'): 1, ('learn', 'ml', 'natur'): 1, ('ml', 'natur', 'languag'): 1, ('process', 'nlp', 'present'): 1, ('nlp', 'present', 'the'): 1, ('present', 'the', 'document'): 1, ('the', 'document', 'structur'): 1, ('document', 'structur', 'two'): 1, ('structur', 'two', 'part'): 1, ('two', 'part', 'the'): 1, ('part', 'the', 'first'): 1, ('the', 'first', 'part'): 1, ('first', 'part', 'includ'): 1, ('part', 'includ', 'superfici'): 1, ('includ', 'superfici', 'comprehens'): 1, ('superfici', 'comprehens', 'survey'): 1, ('comprehens', 'survey', 'cover'): 1, ('survey', 'cover', 'stateoftheart'): 1, ('cover', 'stateoftheart', 'machin'): 1, ('stateoftheart', 'machin', 'learn'): 1, ('abstract', 'thi', 'thesi'): 1, ('thi', 'thesi', 'examin'): 1, ('thesi', 'examin', 'use'): 1, ('examin', 'use', 'machin'): 1, ('use', 'machin', 'learn'): 1, ('learn', 'techniqu', 'variou'): 1, ('techniqu', 'variou', 'task'): 1, ('variou', 'task', 'natur'): 1, ('task', 'natur', 'languag'): 1, ('languag', 'process', 'mainli'): 1, ('process', 'mainli', 'task'): 1, ('mainli', 'task', 'inform'): 1, ('task', 'inform', 'extract'): 1, ('inform', 'extract', 'text'): 1, ('extract', 'text', 'the'): 1, ('text', 'the', 'object'): 1, ('the', 'object', 'improv'): 1, ('object', 'improv', 'adapt'): 1, ('improv', 'adapt', 'inform'): 1, ('adapt', 'inform', 'extract'): 1, ('inform', 'extract', 'system'): 1, ('extract', 'system', 'new'): 1, ('system', 'new', 'themat'): 1, ('new', 'themat', 'domain'): 1, ('themat', 'domain', 'even'): 1, ('tradit', 'approach', 'tointerpret'): 1, ('approach', 'tointerpret', 'natur'): 1, ('tointerpret', 'natur', 'languag'): 1, ('languag', 'process', 'typic'): 1, ('process', 'typic', 'fall'): 1, ('typic', 'fall', 'one'): 1, ('fall', 'one', 'three'): 1, ('one', 'three', 'class'): 1, ('three', 'class', 'syntaxdriven'): 1, ('class', 'syntaxdriven', 'semanticsdriven'): 1, ('syntaxdriven', 'semanticsdriven', 'frametask'): 1, ('semanticsdriven', 'frametask', 'base'): 1, ('frametask', 'base', 'syntaxdriven'): 1, ('base', 'syntaxdriven', 'approach'): 1, ('syntaxdriven', 'approach', 'use'): 1, ('approach', 'use', 'domainindepend'): 1, ('use', 'domainindepend', 'grammar'): 1, ('domainindepend', 'grammar', 'drive'): 1, ('grammar', 'drive', 'interpret'): 1, ('drive', 'interpret', 'process'): 1, ('interpret', 'process', 'produc'): 1, ('process', 'produc', 'global'): 1, ('produc', 'global', 'par'): 1, ('process', 'nlp', 'larg'): 1, ('nlp', 'larg', 'diver'): 1, ('larg', 'diver', 'subtop'): 1, ('diver', 'subtop', 'artifici'): 1, ('subtop', 'artifici', 'intellig'): 1, ('artifici', 'intellig', 'a'): 1, ('intellig', 'a', 'result'): 1, ('a', 'result', 'nlp'): 1, ('result', 'nlp', 'mani'): 1, ('nlp', 'mani', 'subtop'): 1, ('mani', 'subtop', 'includ'): 1, ('subtop', 'includ', 'optic'): 1, ('includ', 'optic', 'charact'): 1, ('optic', 'charact', 'recognit'): 1, ('charact', 'recognit', 'text'): 1, ('recognit', 'text', 'speech'): 1, ('text', 'speech', 'translat'): 1, ('speech', 'translat', 'foreign'): 1, ('translat', 'foreign', 'languag'): 1, ('foreign', 'languag', 'read'): 1, ('languag', 'read', 'write'): 1, ('read', 'write', 'aid'): 1, ('write', 'aid', 'machin'): 1, ('aid', 'machin', 'translat'): 1, ('machin', 'translat', 'speech'): 1, ('translat', 'speech', 'recognit'): 1, ('probabilist', 'finitest', 'string'): 1, ('finitest', 'string', 'transduc'): 1, ('string', 'transduc', 'fst'): 1, ('transduc', 'fst', 'extrem'): 1, ('fst', 'extrem', 'popular'): 1, ('extrem', 'popular', 'natur'): 1, ('popular', 'natur', 'languag'): 1, ('languag', 'process', 'due'): 1, ('process', 'due', 'power'): 1, ('due', 'power', 'gener'): 1, ('power', 'gener', 'method'): 1, ('gener', 'method', 'appli'): 1, ('method', 'appli', 'compos'): 1, ('appli', 'compos', 'learn'): 1, ('compos', 'learn', 'unfortun'): 1, ('learn', 'unfortun', 'fst'): 1, ('unfortun', 'fst', 'good'): 1, ('fst', 'good', 'fit'): 1, ('good', 'fit', 'much'): 1, ('fit', 'much', 'current'): 1, ('much', 'current', 'work'): 1, ('current', 'work', 'probabilist'): 1, ('work', 'probabilist', 'model'): 1, ('probabilist', 'model', 'machin'): 1, ('abstract', 'in', 'special'): 1, ('in', 'special', 'issu'): 1, ('special', 'issu', 'tal'): 1, ('issu', 'tal', 'look'): 1, ('tal', 'look', 'fundament'): 1, ('look', 'fundament', 'principl'): 1, ('fundament', 'principl', 'underli'): 1, ('principl', 'underli', 'evalu'): 1, ('underli', 'evalu', 'natur'): 1, ('evalu', 'natur', 'languag'): 1, ('process', 'we', 'adopt'): 1, ('we', 'adopt', 'global'): 1, ('adopt', 'global', 'point'): 1, ('global', 'point', 'view'): 1, ('point', 'view', 'goe'): 1, ('view', 'goe', 'beyond'): 1, ('goe', 'beyond', 'horizon'): 1, ('beyond', 'horizon', 'singl'): 1, ('horizon', 'singl', 'evalu'): 1, ('singl', 'evalu', 'campaign'): 1, ('evalu', 'campaign', 'particular'): 1, ('campaign', 'particular', 'protocol'): 1, ('particular', 'protocol', 'after'): 1, ('protocol', 'after', 'brief'): 1, ('after', 'brief', 'review'): 1, ('brief', 'review', 'histori'): 1, ('review', 'histori', 'terminolog'): 1, ('process', 'system', 'nlp'): 1, ('system', 'nlp', 'extract'): 1, ('nlp', 'extract', 'clinic'): 1, ('extract', 'clinic', 'inform'): 1, ('clinic', 'inform', 'textual'): 1, ('inform', 'textual', 'report'): 1, ('textual', 'report', 'shown'): 1, ('report', 'shown', 'effect'): 1, ('shown', 'effect', 'limit'): 1, ('effect', 'limit', 'domain'): 1, ('limit', 'domain', 'particular'): 1, ('domain', 'particular', 'applic'): 1, ('particular', 'applic', 'becaus'): 1, ('applic', 'becaus', 'nlp'): 1, ('becaus', 'nlp', 'system'): 1, ('nlp', 'system', 'typic'): 1, ('system', 'typic', 'requir'): 1, ('typic', 'requir', 'substanti'): 1, ('requir', 'substanti', 'resourc'): 1, ('substanti', 'resourc', 'develop'): 1, ('resourc', 'develop', 'benefici'): 1, ('develop', 'benefici', 'design'): 1, ('benefici', 'design', 'easili'): 1, ('fact', 'form', 'link'): 1, ('form', 'link', 'ie'): 1, ('link', 'ie', 'recent'): 1, ('ie', 'recent', 'develop'): 1, ('logic', 'program', 'prolog'): 1, ('we', 'describ', 'singl'): 1, ('describ', 'singl', 'convolut'): 1, ('singl', 'convolut', 'neural'): 1, ('convolut', 'neural', 'network'): 1, ('network', 'architectur', 'given'): 1, ('architectur', 'given', 'sentenc'): 1, ('given', 'sentenc', 'output'): 1, ('sentenc', 'output', 'host'): 1, ('output', 'host', 'languag'): 1, ('host', 'languag', 'process'): 1, ('languag', 'process', 'predict'): 1, ('process', 'predict', 'partofspeech'): 1, ('predict', 'partofspeech', 'tag'): 1, ('name', 'entiti', 'tag'): 1, ('entiti', 'tag', 'semant'): 1, ('tag', 'semant', 'role'): 1, ('semant', 'role', 'semant'): 1, ('role', 'semant', 'similar'): 1, ('semant', 'similar', 'word'): 1, ('similar', 'word', 'likelihood'): 1, ('word', 'likelihood', 'sentenc'): 1, ('likelihood', 'sentenc', 'make'): 1, ('sentenc', 'make', 'sen'): 1, ('make', 'sen', 'grammat'): 1, ('we', 'develop', 'prototyp'): 1, ('develop', 'prototyp', 'inform'): 1, ('prototyp', 'inform', 'retriev'): 1, ('retriev', 'system', 'use'): 1, ('system', 'use', 'advanc'): 1, ('use', 'advanc', 'natur'): 1, ('advanc', 'natur', 'languag'): 1, ('process', 'techniqu', 'enhanc'): 1, ('techniqu', 'enhanc', 'effect'): 1, ('enhanc', 'effect', 'tradit'): 1, ('effect', 'tradit', 'keyword'): 1, ('tradit', 'keyword', 'base'): 1, ('keyword', 'base', 'document'): 1, ('base', 'document', 'retriev'): 1, ('document', 'retriev', 'the'): 1, ('retriev', 'the', 'backbon'): 1, ('the', 'backbon', 'system'): 1, ('backbon', 'system', 'statist'): 1, ('system', 'statist', 'retriev'): 1, ('statist', 'retriev', 'engin'): 1, ('retriev', 'engin', 'perform'): 1, ('engin', 'perform', 'autom'): 1, ('perform', 'autom', 'index'): 1, ('in', 'paper', 'discus'): 1, ('paper', 'discus', 'sever'): 1, ('discus', 'sever', 'issu'): 1, ('sever', 'issu', 'requir'): 1, ('issu', 'requir', 'enabl'): 1, ('requir', 'enabl', 'natur'): 1, ('enabl', 'natur', 'languag'): 1, ('process', 'system', 'becom'): 1, ('system', 'becom', 'contextadapt'): 1, ('becom', 'contextadapt', 'given'): 1, ('contextadapt', 'given', 'fact'): 1, ('given', 'fact', 'emerg'): 1, ('fact', 'emerg', 'system'): 1, ('emerg', 'system', 'featur'): 1, ('system', 'featur', 'speaker'): 1, ('featur', 'speaker', 'independ'): 1, ('speaker', 'independ', 'continu'): 1, ('independ', 'continu', 'speech'): 1, ('continu', 'speech', 'recognit'): 1, ('speech', 'recognit', 'restrict'): 1, ('recognit', 'restrict', 'individu'): 1, ('restrict', 'individu', 'domain'): 1, ('individu', 'domain', 'equip'): 1, ('domain', 'equip', 'syntact'): 1, ('in', 'fall', 'i'): 1, ('fall', 'i', 'introduc'): 1, ('i', 'introduc', 'new'): 1, ('introduc', 'new', 'cours'): 1, ('new', 'cours', 'call'): 1, ('cours', 'call', 'appli'): 1, ('call', 'appli', 'natur'): 1, ('appli', 'natur', 'languag'): 1, ('languag', 'process', 'student'): 1, ('process', 'student', 'acquir'): 1, ('student', 'acquir', 'understand'): 1, ('acquir', 'understand', 'text'): 1, ('understand', 'text', 'analysi'): 1, ('text', 'analysi', 'techniqu'): 1, ('analysi', 'techniqu', 'current'): 1, ('techniqu', 'current', 'feasibl'): 1, ('current', 'feasibl', 'practic'): 1, ('feasibl', 'practic', 'applic'): 1, ('languag', 'process', 'studi'): 1, ('process', 'studi', 'mathemat'): 1, ('studi', 'mathemat', 'comput'): 1, ('mathemat', 'comput', 'model'): 1, ('comput', 'model', 'variou'): 1, ('model', 'variou', 'aspect'): 1, ('variou', 'aspect', 'languag'): 1, ('aspect', 'languag', 'improv'): 1, ('languag', 'improv', 'wide'): 1, ('improv', 'wide', 'rang'): 1, ('wide', 'rang', 'system'): 1, ('rang', 'system', 'natur'): 1, ('system', 'natur', 'languag'): 1, ('languag', 'languag', 'aris'): 1, ('languag', 'aris', 'innat'): 1, ('aris', 'innat', 'facil'): 1, ('innat', 'facil', 'languag'): 1, ('facil', 'languag', 'posse'): 1, ('languag', 'posse', 'human'): 1, ('posse', 'human', 'intellect'): 1, ('human', 'intellect', 'may'): 1, ('process', 'nlp', 'branch'): 1, ('nlp', 'branch', 'artifici'): 1, ('branch', 'artifici', 'intellig'): 1, ('artifici', 'intellig', 'includ'): 1, ('intellig', 'includ', 'speech'): 1, ('includ', 'speech', 'synthesi'): 1, ('speech', 'synthesi', 'speech'): 1, ('synthesi', 'speech', 'recognit'): 1, ('speech', 'recognit', 'machin'): 1, ('recognit', 'machin', 'translat'): 1, ('machin', 'translat', 'natur'): 1, ('translat', 'natur', 'languag'): 1, ('languag', 'process', 'wide'): 1, ('process', 'wide', 'rang'): 1, ('wide', 'rang', 'applic'): 1, ('rang', 'applic', 'indian'): 1, ('applic', 'indian', 'context'): 1, ('indian', 'context', 'most'): 1, ('context', 'most', 'rural'): 1, ('most', 'rural', 'indian'): 1, ('rural', 'indian', 'commun'): 1, ('indian', 'commun', 'unabl'): 1, ('commun', 'unabl', 'make'): 1, ('unabl', 'make', 'use'): 1, ('an', 'evalu', 'lolita'): 1, ('evalu', 'lolita', 'relat'): 1, ('lolita', 'relat', 'natur'): 1, ('process', 'system', 'paul'): 1, ('system', 'paul', 'callaghan'): 1, ('paul', 'callaghan', 'submit'): 1, ('callaghan', 'submit', 'univers'): 1, ('submit', 'univers', 'durham'): 1, ('univers', 'durham', 'degre'): 1, ('durham', 'degre', 'phd'): 1, ('degre', 'phd', 'august'): 1, ('phd', 'august', 'thi'): 1, ('august', 'thi', 'research'): 1, ('thi', 'research', 'address'): 1, ('research', 'address', 'question'): 1, ('address', 'question', 'evalu'): 1, ('question', 'evalu', 'system'): 1, ('evalu', 'system', 'like'): 1, ('system', 'like', 'lolita'): 1, ('like', 'lolita', 'lolita'): 1, ('lolita', 'lolita', 'natur'): 1, ('previou', 'work', 'demonstr'): 1, ('work', 'demonstr', 'web'): 1, ('demonstr', 'web', 'count'): 1, ('web', 'count', 'use'): 1, ('count', 'use', 'approxim'): 1, ('use', 'approxim', 'bigram'): 1, ('approxim', 'bigram', 'count'): 1, ('bigram', 'count', 'suggest'): 1, ('count', 'suggest', 'webbas'): 1, ('suggest', 'webbas', 'frequenc'): 1, ('webbas', 'frequenc', 'use'): 1, ('frequenc', 'use', 'wide'): 1, ('use', 'wide', 'varieti'): 1, ('wide', 'varieti', 'natur'): 1, ('varieti', 'natur', 'languag'): 1, ('nlp', 'task', 'howev'): 1, ('task', 'howev', 'limit'): 1, ('howev', 'limit', 'number'): 1, ('limit', 'number', 'task'): 1, ('number', 'task', 'far'): 1, ('task', 'far', 'test'): 1, ('far', 'test', 'use'): 1, ('test', 'use', 'webscal'): 1, ('use', 'webscal', 'data'): 1, ('webscal', 'data', 'set'): 1, ('develop', 'opportun', 'introduct'): 1, ('opportun', 'introduct', 'thi'): 1, ('introduct', 'thi', 'chapter'): 1, ('thi', 'chapter', 'focus'): 1, ('chapter', 'focus', 'applic'): 1, ('thi', 'paper', 'describ'): 1, ('paper', 'describ', 'natur'): 1, ('describ', 'natur', 'languag'): 1, ('natur', 'languag', 'system'): 1, ('languag', 'system', 'improv'): 1, ('system', 'improv', 'perform'): 1, ('improv', 'perform', 'learn'): 1, ('perform', 'learn', 'the'): 1, ('learn', 'the', 'system'): 1, ('the', 'system', 'process'): 1, ('system', 'process', 'short'): 1, ('process', 'short', 'english'): 1, ('short', 'english', 'narr'): 1, ('english', 'narr', 'abl'): 1, ('narr', 'abl', 'acquir'): 1, ('abl', 'acquir', 'singl'): 1, ('acquir', 'singl', 'narr'): 1, ('singl', 'narr', 'new'): 1, ('narr', 'new', 'schema'): 1, ('new', 'schema', 'stereotyp'): 1, ('schema', 'stereotyp', 'set'): 1, ('stereotyp', 'set', 'action'): 1, ('set', 'action', 'dure'): 1, ('action', 'dure', 'understand'): 1, ('dure', 'understand', 'process'): 1, ('understand', 'process', 'system'): 1, ('process', 'system', 'attempt'): 1, ('we', 'classifi', 'review'): 1, ('classifi', 'review', 'current'): 1, ('review', 'current', 'approach'): 1, ('current', 'approach', 'softwar'): 1, ('approach', 'softwar', 'infrastructur'): 1, ('softwar', 'infrastructur', 'research'): 1, ('infrastructur', 'research', 'develop'): 1, ('research', 'develop', 'deliveri'): 1, ('develop', 'deliveri', 'nlp'): 1, ('deliveri', 'nlp', 'system'): 1, ('nlp', 'system', 'the'): 1, ('system', 'the', 'task'): 1, ('confid', 'measur', 'practic'): 1, ('measur', 'practic', 'solut'): 1, ('practic', 'solut', 'improv'): 1, ('solut', 'improv', 'use'): 1, ('improv', 'use', 'natur'): 1, ('process', 'applic', 'confid'): 1, ('confid', 'estim', 'gener'): 1, ('estim', 'gener', 'machin'): 1, ('gener', 'machin', 'learn'): 1, ('machin', 'learn', 'approach'): 1, ('learn', 'approach', 'deriv'): 1, ('approach', 'deriv', 'confid'): 1, ('deriv', 'confid', 'measur'): 1, ('confid', 'measur', 'we'): 1, ('measur', 'we', 'give'): 1, ('we', 'give', 'overview'): 1, ('give', 'overview', 'applic'): 1, ('overview', 'applic', 'confid'): 1, ('confid', 'estim', 'variou'): 1, ('estim', 'variou', 'field'): 1, ('senseid', 'senseid', 'dictionari'): 1, ('senseid', 'dictionari', 'ldoce'): 1, ('dictionari', 'ldoce', 'lexsign'): 1, ('ldoce', 'lexsign', 'senseid'): 1, ('senseid', 'senseid', 'ldbentryno'): 1, ('senseid', 'ldbentryno', 'lexsign'): 1, ('ldbentryno', 'lexsign', 'senseid'): 1, ('senseid', 'senseid', 'senseno'): 1, ('senseid', 'senseno', 'when'): 1, ('senseno', 'when', 'load'): 1, ('when', 'load', 'lkb'): 1, ('load', 'lkb', 'expand'): 1, ('lkb', 'expand', 'fullyfledg'): 1, ('expand', 'fullyfledg', 'represent'): 1, ('fullyfledg', 'represent', 'transit'): 1, ('represent', 'transit', 'use'): 1, ('transit', 'use', 'experi'): 1, ('use', 'experi', 'integr'): 1, ('experi', 'integr', 'wordspecif'): 1, ('integr', 'wordspecif', 'inform'): 1, ('wordspecif', 'inform', 'provid'): 1, ('inform', 'provid', 'inform'): 1, ('provid', 'inform', 'encod'): 1, ('inform', 'encod', 'lkb'): 1, ('encod', 'lkb', 'type'): 1, ('lkb', 'type', 'stricttranssign'): 1, ('type', 'stricttranssign', 'thu'): 1, ('stricttranssign', 'thu', 'although'): 1, ('thu', 'although', 'neither'): 1, ('although', 'neither', 'ldoce'): 1, ('neither', 'ldoce', 'llce'): 1, ('ldoce', 'llce', 'earlier'): 1, ('llce', 'earlier', 'subcategoris'): 1, ('earlier', 'subcategoris', 'lexicon'): 1, ('subcategoris', 'lexicon', 'contain'): 1, ('lexicon', 'contain', 'inform'): 1, ('contain', 'inform', 'psycholog'): 1, ('inform', 'psycholog', 'verb'): 1, ('psycholog', 'verb', 'defin'): 1, ('verb', 'defin', 'sanfilippoaposs'): 1, ('defin', 'sanfilippoaposs', 'type'): 1, ('sanfilippoaposs', 'type', 'system'): 1, ('type', 'system', 'use'): 1, ('system', 'use', 'conjunct'): 1, ('use', 'conjunct', 'inform'): 1, ('conjunct', 'inform', 'avail'): 1, ('inform', 'avail', 'three'): 1, ('avail', 'three', 'prove'): 1, ('three', 'prove', 'possibl'): 1, ('prove', 'possibl', 'effect'): 1, ('possibl', 'effect', 'enrich'): 1, ('effect', 'enrich', 'inform'): 1, ('enrich', 'inform', 'time'): 1, ('inform', 'time', 'map'): 1, ('time', 'map', 'formal'): 1, ('map', 'formal', 'represent'): 1, ('formal', 'represent', 'toward'): 1, ('represent', 'toward', 'multilingu'): 1, ('toward', 'multilingu', 'lkb'): 1, ('multilingu', 'lkb', 'a'): 1, ('lkb', 'a', 'goal'): 1, ('a', 'goal', 'acquilex'): 1, ('goal', 'acquilex', 'demonstr'): 1, ('acquilex', 'demonstr', 'lkb'): 1, ('demonstr', 'lkb', 'produc'): 1, ('lkb', 'produc', 'use'): 1, ('produc', 'use', 'exploit'): 1, ('use', 'exploit', 'variou'): 1, ('exploit', 'variou', 'mrd'): 1, ('variou', 'mrd', 'sourc'): 1, ('mrd', 'sourc', 'integr'): 1, ('sourc', 'integr', 'multilingu'): 1, ('integr', 'multilingu', 'inform'): 1, ('multilingu', 'inform', 'the'): 1, ('inform', 'the', 'use'): 1, ('the', 'use', 'common'): 1, ('use', 'common', 'lrl'): 1, ('common', 'lrl', 'common'): 1, ('lrl', 'common', 'type'): 1, ('common', 'type', 'system'): 1, ('type', 'system', 'make'): 1, ('system', 'make', 'possi'): 1, ('we', 'describ', 'design'): 1, ('describ', 'design', 'use'): 1, ('design', 'use', 'stanford'): 1, ('use', 'stanford', 'corenlp'): 1, ('stanford', 'corenlp', 'toolkit'): 1, ('corenlp', 'toolkit', 'extens'): 1, ('toolkit', 'extens', 'pipelin'): 1, ('extens', 'pipelin', 'provid'): 1, ('pipelin', 'provid', 'core'): 1, ('provid', 'core', 'natur'): 1, ('core', 'natur', 'languag'): 1, ('natur', 'languag', 'analysi'): 1, ('languag', 'analysi', 'thi'): 1, ('analysi', 'thi', 'toolkit'): 1, ('thi', 'toolkit', 'quit'): 1, ('toolkit', 'quit', 'wide'): 1, ('quit', 'wide', 'use'): 1, ('wide', 'use', 'research'): 1, ('use', 'research', 'nlp'): 1, ('research', 'nlp', 'commun'): 1, ('nlp', 'commun', 'also'): 1, ('commun', 'also', 'among'): 1, ('also', 'among', 'commerci'): 1, ('among', 'commerci', 'govern'): 1, ('commerci', 'govern', 'user'): 1, ('govern', 'user', 'open'): 1, ('user', 'open', 'sourc'): 1, ('open', 'sourc', 'nlp'): 1, ('sourc', 'nlp', 'technolog'): 1, ('nlp', 'technolog', 'we'): 1, ('technolog', 'we', 'suggest'): 1, ('gaussian', 'process', 'gp'): 1, ('process', 'gp', 'power'): 1, ('gp', 'power', 'model'): 1, ('power', 'model', 'framework'): 1, ('model', 'framework', 'incorpor'): 1, ('framework', 'incorpor', 'kernel'): 1, ('incorpor', 'kernel', 'bayesian'): 1, ('kernel', 'bayesian', 'infer'): 1, ('bayesian', 'infer', 'recognis'): 1, ('infer', 'recognis', 'stateoftheart'): 1, ('recognis', 'stateoftheart', 'mani'): 1, ('stateoftheart', 'mani', 'machin'): 1, ('mani', 'machin', 'learn'): 1, ('machin', 'learn', 'task'): 1, ('a', 'fundament', 'issu'): 1, ('fundament', 'issu', 'natur'): 1, ('issu', 'natur', 'languag'): 1, ('languag', 'process', 'prerequisit'): 1, ('process', 'prerequisit', 'enorm'): 1, ('prerequisit', 'enorm', 'quantiti'): 1, ('enorm', 'quantiti', 'preprogram'): 1, ('quantiti', 'preprogram', 'knowledg'): 1, ('preprogram', 'knowledg', 'concern'): 1, ('knowledg', 'concern', 'languag'): 1, ('concern', 'languag', 'domain'): 1, ('languag', 'domain', 'examin'): 1, ('domain', 'examin', 'manual'): 1, ('examin', 'manual', 'acquisit'): 1, ('manual', 'acquisit', 'knowledg'): 1, ('acquisit', 'knowledg', 'tediou'): 1, ('knowledg', 'tediou', 'error'): 1, ('tediou', 'error', 'prone'): 1, ('error', 'prone', 'develop'): 1, ('prone', 'develop', 'autom'): 1, ('develop', 'autom', 'acquisit'): 1, ('support', 'sophist', 'natur'): 1, ('sophist', 'natur', 'languag'): 1, ('languag', 'process', 'significantli'): 1, ('process', 'significantli', 'simplifi'): 1, ('significantli', 'simplifi', 'interfac'): 1, ('simplifi', 'interfac', 'domainspecif'): 1, ('interfac', 'domainspecif', 'knowledg'): 1, ('domainspecif', 'knowledg', 'gener'): 1, ('knowledg', 'gener', 'lingui'): 1, ('gener', 'lingui', 'tic'): 1, ('lingui', 'tic', 'resourc'): 1, ('tic', 'resourc', 'thi'): 1, ('resourc', 'thi', 'paper'): 1, ('paper', 'present', 'result'): 1, ('present', 'result', 'experi'): 1, ('result', 'experi', 'design'): 1, ('experi', 'design', 'use'): 1, ('design', 'use', 'upper'): 1, ('use', 'upper', 'model'): 1, ('upper', 'model', 'varieti'): 1, ('model', 'varieti', 'applic'): 1, ('varieti', 'applic', 'past'): 1, ('applic', 'past', 'year'): 1, ('neighbor', 'map', 'node'): 1, ('map', 'node', 'node'): 1, ('node', 'node', 'may'): 1, ('node', 'may', 'thu'): 1, ('may', 'thu', 'view'): 1, ('thu', 'view', 'word'): 1, ('view', 'word', 'categori'): 1, ('word', 'categori', 'although'): 1, ('categori', 'although', 'priori'): 1, ('although', 'priori', 'inform'): 1, ('priori', 'inform', 'class'): 1, ('inform', 'class', 'given'): 1, ('class', 'given', 'selforgan'): 1, ('given', 'selforgan', 'process'): 1, ('selforgan', 'process', 'model'): 1, ('process', 'model', 'word'): 1, ('model', 'word', 'class'): 1, ('word', 'class', 'emerg'): 1, ('class', 'emerg', 'the'): 1, ('emerg', 'the', 'central'): 1, ('the', 'central', 'topic'): 1, ('central', 'topic', 'thesi'): 1, ('topic', 'thesi', 'use'): 1, ('thesi', 'use', 'som'): 1, ('use', 'som', 'natur'): 1, ('som', 'natur', 'languag'): 1, ('process', 'the', 'approach'): 1, ('paper', 'present', 'workbench'): 1, ('present', 'workbench', 'built'): 1, ('workbench', 'built', 'priberam'): 1, ('built', 'priberam', 'informtica'): 1, ('priberam', 'informtica', 'develop'): 1, ('informtica', 'develop', 'compani'): 1, ('develop', 'compani', 'natur'): 1, ('compani', 'natur', 'languag'): 1, ('languag', 'process', 'technolog'): 1, ('process', 'technolog', 'thi'): 1, ('technolog', 'thi', 'workbench'): 1, ('thi', 'workbench', 'includ'): 1, ('workbench', 'includ', 'set'): 1, ('includ', 'set', 'linguist'): 1, ('set', 'linguist', 'resourc'): 1, ('linguist', 'resourc', 'softwar'): 1, ('resourc', 'softwar', 'tool'): 1, ('softwar', 'tool', 'appli'): 1, ('tool', 'appli', 'consider'): 1, ('appli', 'consider', 'number'): 1, ('consider', 'number', 'practic'): 1, ('number', 'practic', 'purpos'): 1, ('practic', 'purpos', 'cover'): 1, ('process', 'nlp', 'effect'): 1, ('nlp', 'effect', 'approach'): 1, ('effect', 'approach', 'bring'): 1, ('approach', 'bring', 'improv'): 1, ('bring', 'improv', 'educ'): 1, ('improv', 'educ', 'set'): 1, ('educ', 'set', 'implement'): 1, ('set', 'implement', 'nlp'): 1, ('implement', 'nlp', 'involv'): 1, ('nlp', 'involv', 'initi'): 1, ('involv', 'initi', 'process'): 1, ('initi', 'process', 'learn'): 1, ('process', 'learn', 'natur'): 1, ('learn', 'natur', 'acquisit'): 1, ('natur', 'acquisit', 'educ'): 1, ('acquisit', 'educ', 'system'): 1, ('educ', 'system', 'it'): 1, ('system', 'it', 'base'): 1, ('it', 'base', 'effect'): 1, ('base', 'effect', 'approach'): 1, ('effect', 'approach', 'provid'): 1, ('approach', 'provid', 'solut'): 1, ('abstract', 'after', 'twenti'): 1, ('after', 'twenti', 'year'): 1, ('twenti', 'year', 'disfavor'): 1, ('year', 'disfavor', 'technolog'): 1, ('disfavor', 'technolog', 'return'): 1, ('technolog', 'return', 'imit'): 1, ('return', 'imit', 'process'): 1, ('imit', 'process', 'brain'): 1, ('process', 'brain', 'natur'): 1, ('brain', 'natur', 'languag'): 1, ('natur', 'languag', 'experi'): 1, ('languag', 'experi', 'sejnowski'): 1, ('experi', 'sejnowski', 'rosenberg'): 1, ('sejnowski', 'rosenberg', 'demonstr'): 1, ('rosenberg', 'demonstr', 'neural'): 1, ('demonstr', 'neural', 'network'): 1, ('neural', 'network', 'comput'): 1, ('network', 'comput', 'architectur'): 1, ('comput', 'architectur', 'learn'): 1, ('architectur', 'learn', 'actual'): 1, ('learn', 'actual', 'spoken'): 1, ('actual', 'spoken', 'languag'): 1, ('spoken', 'languag', 'observ'): 1, ('languag', 'observ', 'rule'): 1, ('observ', 'rule', 'pronunci'): 1, ('text', 'statist', 'frequent'): 1, ('statist', 'frequent', 'use'): 1, ('frequent', 'use', 'stylometri'): 1, ('use', 'stylometri', 'cryptographi'): 1, ('stylometri', 'cryptographi', 'studi'): 1, ('cryptographi', 'studi', 'in'): 1, ('studi', 'in', 'paper'): 1, ('in', 'paper', 'text'): 1, ('paper', 'text', 'statist'): 1, ('text', 'statist', 'tool'): 1, ('statist', 'tool', 'develop'): 1, ('tool', 'develop', 'iso'): 1, ('develop', 'iso', 'prolog'): 1, ('iso', 'prolog', 'natur'): 1, ('prolog', 'natur', 'languag'): 1, ('languag', 'process', 'detail'): 1, ('process', 'detail', 'given'): 1, ('detail', 'given', 'usag'): 1, ('given', 'usag', 'usercal'): 1, ('usag', 'usercal', 'predic'): 1, ('usercal', 'predic', 'logic'): 1, ('predic', 'logic', 'limit'): 1, ('logic', 'limit', 'program'): 1, ('limit', 'program', 'also'): 1, ('program', 'also', 'discus'): 1, ('we', 'summar', 'experi'): 1, ('summar', 'experi', 'use'): 1, ('experi', 'use', 'framenet'): 1, ('use', 'framenet', 'two'): 1, ('framenet', 'two', 'rather'): 1, ('two', 'rather', 'differ'): 1, ('rather', 'differ', 'project'): 1, ('differ', 'project', 'natur'): 1, ('project', 'natur', 'languag'): 1, ('process', 'nlp', 'we'): 1, ('nlp', 'we', 'conclud'): 1, ('we', 'conclud', 'nlp'): 1, ('conclud', 'nlp', 'benefit'): 1, ('nlp', 'benefit', 'framenet'): 1, ('benefit', 'framenet', 'differ'): 1, ('framenet', 'differ', 'way'): 1, ('differ', 'way', 'sketch'): 1, ('way', 'sketch', 'problem'): 1, ('sketch', 'problem', 'need'): 1, ('problem', 'need', 'overcom'): 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nd2DIwKmYmC"
      },
      "source": [
        "n-grams are used for a variety of things. Some examples include auto completion of sentences (such as the one we see in Gmail these days)\n",
        ", auto spell check (yes, we can do that as well), and to a certain extent, we can check for grammar in a given sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg1HCswJnO4l"
      },
      "source": [
        "Suppose were calculating the probability of word w1 occurring after the word w2, then the formula for this is as follows: count(w2 w1)/ count(w2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKy5K7lpj05X"
      },
      "source": [
        "TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y58LR74ujzhy"
      },
      "source": [
        "df['biGrams_Article'] = df['WordToken_Article'].apply(lambda x: list (ngrams(x,2)))\n",
        "df['biGrams_Abstract'] = df['WordToken_Abstract'].apply(lambda x: list (ngrams(x,2)))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJJvZcyyjA5T"
      },
      "source": [
        "lis_biGrams_Article = list (chain(*df['biGrams_Article']))\n",
        "lis_biGrams_Abstract = list (chain(*df['biGrams_Abstract']))\n",
        "coun_biGrams_Article = Counter(lis_biGrams_Article)\n",
        "coun_biGrams_Abstract = Counter(lis_biGrams_Abstract)\n",
        "key_biGrams_Article = [ ]\n",
        "key_biGrams_Abstract = [ ]\n",
        "for key in coun_biGrams_Article.keys() :\n",
        "   key_biGrams_Article.append(key)\n",
        "for key in coun_biGrams_Abstract.keys() : \n",
        "   key_biGrams_Abstract.append(key)\n",
        "coun_biGrams_Article_Values = [] \n",
        "coun_biGrams_Abstract_Values = [ ]\n",
        "for key in coun_biGrams_Article.keys() : \n",
        "    coun_biGrams_Article_Values.append(coun_biGrams_Article[key]) \n",
        "for key in coun_biGrams_Abstract.keys() : \n",
        "    coun_biGrams_Abstract_Values.append(coun_biGrams_Abstract[key]) \n",
        "df2 = pd.DataFrame({'biGrams_Article': key_biGrams_Article,'count_biGrams_Article':coun_biGrams_Article_Values})\n",
        "df3 = pd.DataFrame({'biGrams_Abstract':key_biGrams_Abstract,'count_biGrams_Abstract':coun_biGrams_Abstract_Values})"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDATnyeqAZxs",
        "outputId": "4d011810-aad1-47d0-91fc-1977493eb4d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>biGrams_Article</th>\n",
              "      <th>count_biGrams_Article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(foundat, statist)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(statist, natur)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(natur, languag)</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(languag, process)</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(a, maximum)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      biGrams_Article  count_biGrams_Article\n",
              "0  (foundat, statist)                      1\n",
              "1    (statist, natur)                      2\n",
              "2    (natur, languag)                     99\n",
              "3  (languag, process)                     98\n",
              "4        (a, maximum)                      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrWI2XYKAwfy",
        "outputId": "f884ab6e-cac0-468a-edf1-56867f93ffec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df3.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>biGrams_Abstract</th>\n",
              "      <th>count_biGrams_Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(abstract, found)</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(describ, method)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(method, statist)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(statist, model)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(model, base)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    biGrams_Abstract  count_biGrams_Abstract\n",
              "0  (abstract, found)                       8\n",
              "1  (describ, method)                       1\n",
              "2  (method, statist)                       1\n",
              "3   (statist, model)                       2\n",
              "4      (model, base)                       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bLERo96mHoZ"
      },
      "source": [
        "#Calculate the probabilities for all the bigrams in the dataset by using the fomular count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33\n",
        "\n",
        "df['uniGrams_Article'] = df['WordToken_Article'].apply(lambda x: list (ngrams(x,1)))\n",
        "df['uniGrams_Abstract'] = df['WordToken_Abstract'].apply(lambda x: list (ngrams(x,1)))\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cCD1Zyy1tq0"
      },
      "source": [
        "lis_uniGrams_Article = list (chain(*df['uniGrams_Article']))\n",
        "lis_uniGrams_Abstract = list (chain(*df['uniGrams_Abstract']))\n",
        "\n",
        "coun_uniGrams_Article = Counter(lis_uniGrams_Article)\n",
        "coun_uniGrams_Abstract = Counter(lis_uniGrams_Abstract)\n",
        "\n",
        "key_uniGrams_Article = [ ]\n",
        "key_uniGrams_Abstract = [ ]\n",
        "\n",
        "for key in coun_uniGrams_Article.keys() :\n",
        "   key_uniGrams_Article.append(key)\n",
        "for key in coun_uniGrams_Abstract.keys() : \n",
        "   key_uniGrams_Abstract.append(key)\n",
        "\n",
        "coun_uniGrams_Article_Values = [] \n",
        "coun_uniGrams_Abstract_Values = [ ]\n",
        "\n",
        "\n",
        "for key in coun_uniGrams_Article.keys() : \n",
        "    coun_uniGrams_Article_Values.append(coun_uniGrams_Article[key]) \n",
        "for key in coun_uniGrams_Abstract.keys() : \n",
        "    coun_uniGrams_Abstract_Values.append(coun_uniGrams_Abstract[key]) \n",
        "\n",
        "df4 = pd.DataFrame({'uniGrams_Article': key_uniGrams_Article,'count_uniGrams_Article':coun_uniGrams_Article_Values})\n",
        "df5 = pd.DataFrame({'uniGrams_Abstract':key_uniGrams_Abstract,'count_uniGrams_Abstract':coun_uniGrams_Abstract_Values})"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXSVlkpNB2H1",
        "outputId": "badf3e0b-4264-4340-d74b-2a2bbc30f720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df4.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uniGrams_Article</th>\n",
              "      <th>count_uniGrams_Article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(foundat,)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(statist,)</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(natur,)</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(languag,)</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(process,)</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  uniGrams_Article  count_uniGrams_Article\n",
              "0       (foundat,)                       1\n",
              "1       (statist,)                       4\n",
              "2         (natur,)                      99\n",
              "3       (languag,)                     101\n",
              "4       (process,)                     100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFHCec7OB2S4",
        "outputId": "cce38fc8-816d-40f7-80c7-2623e0007de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df5.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uniGrams_Abstract</th>\n",
              "      <th>count_uniGrams_Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(abstract,)</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(found,)</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(describ,)</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(method,)</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(statist,)</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  uniGrams_Abstract  count_uniGrams_Abstract\n",
              "0       (abstract,)                       19\n",
              "1          (found,)                        8\n",
              "2        (describ,)                       11\n",
              "3         (method,)                        8\n",
              "4        (statist,)                       11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz_sajeCCll9",
        "outputId": "9288b6c1-1d66-4bf5-916c-a704119d43a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(lis_uniGrams_Article[-2:])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('languag',), ('process',)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BoTZyq3Clxq",
        "outputId": "47528fcf-edd7-4a3d-ea41-98508f1f857a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prob_bigrams_Articles = [coun_biGrams_Article_Values[i]/coun_uniGrams_Article_Values[i+1] for i in range(4)]\n",
        "prob_bigrams_Articles"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.25, 0.020202020202020204, 0.9801980198019802, 0.98]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NveAqYWlCl9Z",
        "outputId": "d62cc2f0-80e5-4976-e8b4-fecc07dc3a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prob_bigrams_Abstract = [coun_biGrams_Abstract_Values[i]/coun_uniGrams_Abstract_Values[i+1] for i in range(4)]\n",
        "prob_bigrams_Abstract"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 0.09090909090909091, 0.125, 0.18181818181818182]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8Kwi3dD0Ys-"
      },
      "source": [
        "list_Abstract = df['Abstract'].tolist()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wODhlckN98bY"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "li_WordToken_Abstract = df['WordToken_Abstract'].tolist()\n",
        "df['doc_Abstract'] = df['Abstract'].apply(lambda x: nlp(x) )"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0Jo4aDR50EE"
      },
      "source": [
        "NN_Abstract_text = [ ]\n",
        "for i in df['doc_Abstract']:\n",
        "  for j in i.noun_chunks:\n",
        "     NN_Abstract_text.append(j.text)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwSajNUUC_hI",
        "outputId": "9f47d9fc-8bbb-461b-95d8-1f510feeeee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "NN_Abstract_text"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abstract',\n",
              " 'describ method statist model base',\n",
              " 'maximum entropi',\n",
              " 'we',\n",
              " 'maximumlikelihood approach automat',\n",
              " 'maximum entropi model',\n",
              " 'describ implement approach',\n",
              " 'sever problem natur languag process',\n",
              " 'scale',\n",
              " 'random field natur languag process term condit term',\n",
              " 'copyright work deposit minerva access',\n",
              " 'the paper address issu cooper linguist natur languag process nlp gener',\n",
              " 'linguist machin translat',\n",
              " 'it',\n",
              " 'one direct cooper name applic',\n",
              " 'natur languag process applic descript logic',\n",
              " 'encod knowledg base syntact semant pragmat element',\n",
              " 'natur languag gener process',\n",
              " 'more recent descript logic',\n",
              " 'we',\n",
              " 'neural network architectur',\n",
              " 'algorithm appli',\n",
              " 'variou natur languag process task',\n",
              " 'includ partofspeech',\n",
              " 'tag chunk name',\n",
              " 'entiti recognit semant role label thi versatil achiev tri',\n",
              " 'task',\n",
              " 'natur languag',\n",
              " 'the subject natur languag process',\n",
              " 'narrow sen',\n",
              " 'broad sen cover process issu level natur languag',\n",
              " 'includ speech recognit syntact semant analysi sentenc',\n",
              " 'robot interact human facetofac use',\n",
              " 'natur languag',\n",
              " 'respons',\n",
              " 'human use',\n",
              " 'we',\n",
              " 'natur languag languag',\n",
              " 'human current',\n",
              " 'point languag unprocess form',\n",
              " 'comput natur languag process',\n",
              " 'techniqu',\n",
              " 'tri accomplish goal',\n",
              " 'the field natur',\n",
              " 'abstract ambigu',\n",
              " 'abil',\n",
              " 'one way',\n",
              " 'natur languag ambigu comput abl',\n",
              " 'languag way peopl natur languag process nlp concern',\n",
              " 'introduct',\n",
              " 'statist natur languag process',\n",
              " 'snlp field',\n",
              " 'intersect natur languag process machin',\n",
              " 'snlp dier tradit natur languag process',\n",
              " 'model',\n",
              " 'linguist',\n",
              " 'text directli',\n",
              " 'rather eg',\n",
              " 'titl abstract',\n",
              " 'appropri approach focu role natur languag process',\n",
              " 'the paper',\n",
              " 'data knowledg retriev',\n",
              " 'abstract languag way',\n",
              " 'commun word',\n",
              " 'languag',\n",
              " 'worldw',\n",
              " 'better insight world languag',\n",
              " 'speaker vagu precis',\n",
              " 'nlp stand natur languag process natur languag languag',\n",
              " 'we',\n",
              " 'experi',\n",
              " 'standard natur languag process',\n",
              " 'nlp tool analysi music',\n",
              " 'audio lyric lyric encod',\n",
              " 'analysi complement acoust cultur',\n",
              " 'paper describ',\n",
              " 'rulebas approach autom',\n",
              " 'linguist knowledg thi approach',\n",
              " 'number task',\n",
              " 'captur inform clearer direct fashion',\n",
              " 'we',\n",
              " 'studi',\n",
              " 'method appli part',\n",
              " 'thi paper focus connectionist model natur languag process',\n",
              " 'we',\n",
              " 'present discus sever aspect high level task',\n",
              " 'recent approach connection',\n",
              " 'parallel distribut process model sever interest architectur',\n",
              " 'process languag',\n",
              " 'thi new approach natur languag process base determinist chaotic behavior dynam system',\n",
              " 'paper',\n",
              " 'ka leak owen brief discus program',\n",
              " 'principl goal simpli point interest natur languag process',\n",
              " 'u natur inde inevit',\n",
              " 'object',\n",
              " 'overview',\n",
              " 'natur languag process',\n",
              " 'nlp modern nlpsystem design target audienc thi',\n",
              " 'target medic informat generalist limit acquaint',\n",
              " 'nlp andor limit knowledg current state',\n",
              " 'thi paper briefli describ current implement',\n",
              " 'statu intellig inform retriev system mari employ',\n",
              " 'natur languag process techniqu descript caption use',\n",
              " 'iden tifi photograph imag concern variou militari project',\n",
              " 'the caption par',\n",
              " 'base literatur resourc',\n",
              " 'we',\n",
              " 'system agent direct natur languag process',\n",
              " 'inform journal articl',\n",
              " 'deposit',\n",
              " 'the advent',\n",
              " 'evalu speech process part',\n",
              " 'far instanc',\n",
              " 'machin translat discus particular problem gener system evalu',\n",
              " 'the conclus evalu strategi techniqu nlp',\n",
              " 'similar way human intuit order elimin noisi content',\n",
              " 'paper describ combin html dom analysi natur languag process',\n",
              " 'main articl',\n",
              " 'imag web page',\n",
              " 'abstract natur languag process theoret motiv rang comput techniqu analys',\n",
              " 'natur occur text',\n",
              " 'linguist analysi',\n",
              " 'thi paper review process',\n",
              " 'natur languag process',\n",
              " 'it',\n",
              " 'variou',\n",
              " 'word morpholog',\n",
              " 'text analysi',\n",
              " 'it',\n",
              " 'thi articl focus deriv',\n",
              " 'lexicon natur languag process',\n",
              " 'we',\n",
              " 'dictionari support environ link restructur version longman dictionari contemporari english natur languag process',\n",
              " 'the process',\n",
              " 'we',\n",
              " 'introduc method analyz complex natur languag process task',\n",
              " 'new nlp task',\n",
              " 'our complex measur deriv kolmogorov complex class automaton',\n",
              " 'automaton',\n",
              " 'whose purpos',\n",
              " 'relev piec',\n",
              " 'sound text motion',\n",
              " 'the techniqu',\n",
              " 'research alreadi impact',\n",
              " 'research natur languag process thi paper review',\n",
              " 'recent research',\n",
              " 'natur languag process',\n",
              " 'thi authorproduc version paper',\n",
              " 'abstractnatur languag process',\n",
              " 'applic autom par machin',\n",
              " 'techniqu analyz standard text applic nlp requir engin includ extract',\n",
              " 'ontolog requir specif use nlp verifi',\n",
              " 'statist baselin',\n",
              " 'includ forgiv natur broad coverag typic retriev task',\n",
              " 'good weight scheme compound index term implicit linguist process',\n",
              " 'inher statist method natur languag process techniqu',\n",
              " 'work comput linguist',\n",
              " 'first comput booth brandwood cleav',\n",
              " 'pervas',\n",
              " 'progress comput',\n",
              " 'natur languag commensur',\n",
              " 'voic recognit natur languag',\n",
              " 'combin digit mathemat knowledg',\n",
              " 'mfcc dtw extract',\n",
              " 'abstract test natur languag requir standard approach system',\n",
              " 'test thi test',\n",
              " 'independ test organ unfamiliar applic area',\n",
              " 'the thing tester',\n",
              " 'written requir',\n",
              " 'abstract',\n",
              " 'convers partner',\n",
              " 'u inform creativ',\n",
              " 'make',\n",
              " 'associ storytel languag',\n",
              " 'humor persuad domin soften',\n",
              " 'threaten act',\n",
              " 'abstract',\n",
              " 'recent year',\n",
              " 'machin',\n",
              " 'solv complex task',\n",
              " 'disciplin rang data mine inform',\n",
              " 'we',\n",
              " 'manual automat thesaurus',\n",
              " 'altern resourc',\n",
              " 'task thi',\n",
              " 'involv radic step',\n",
              " 'manual thesaurus classif word',\n",
              " 'rather word sen case',\n",
              " 'nlp briefli present wasp thesauru introduc thesauru evalu becom',\n",
              " 'a rang evalu strategi',\n",
              " 'nlp task propos',\n",
              " 'one purpos analyz music structur form discov pattern explicit implicit music work simon pattern compris period',\n",
              " 'use alphabet compound',\n",
              " 'subpattern posse phrase',\n",
              " 'variou form',\n",
              " 'pattern propag intuit algorithm composit techniqu',\n",
              " 'pattern',\n",
              " 'formal albeit high level dure composit music pattern evolv accord rule constraint speci design stage',\n",
              " 'jazz improvis musician',\n",
              " 'guid progress',\n",
              " 'chord chang',\n",
              " 'one approach',\n",
              " 'improvis memor pattern short chunk music subprogress concaten form',\n",
              " 'whole solo t',\n",
              " 'abstract mani inform retrievalir system retriev relev document base exact match keyword queri document thi method degrad precis rate',\n",
              " 'order solv problem',\n",
              " 'semant relat word assign semant relationship',\n",
              " 'addit semant knowledg automat',\n",
              " 'statist knowledg base concept',\n",
              " 'mutual inform keyfact extend concept keyword repres noun compound noun keyfact verb',\n",
              " 'includ subject object term',\n",
              " 'we',\n",
              " 'relev document origin',\n",
              " 'queri use',\n",
              " 'tf idf weight formula',\n",
              " 'second document rank word sen disambigu',\n",
              " 'precis rate',\n",
              " 'paper argu',\n",
              " 'technic domain distinctli',\n",
              " 'trecbas qa webbas',\n",
              " 'lom dataintens approach',\n",
              " 'universitquotat de saarland',\n",
              " 'proceed workshop',\n",
              " 'unihamburgd',\n",
              " 'abstract',\n",
              " 'abstract',\n",
              " 'sri',\n",
              " 'new architectur integr speech naturallanguag process appli linguist constraint recognit increment',\n",
              " 'statetransit network embodi',\n",
              " 'unif grammar',\n",
              " 'we',\n",
              " 'dynamicgralnlnarnetwork dgn approach',\n",
              " 'thi chapter consid revolut',\n",
              " 'place',\n",
              " 'natur languag process research',\n",
              " 'it',\n",
              " 'provid brief guid structur field',\n",
              " 'environ support',\n",
              " 'visual assembl execut',\n",
              " 'analysi',\n",
              " 'modular natur languag process system',\n",
              " 'the visual model',\n",
              " 'data flow program graph automat synthesis data',\n",
              " 'declar languag process',\n",
              " 'the graph',\n",
              " 'chapter basic use descript logic natur languag process analys',\n",
              " 'littl bit histori role descript logic',\n",
              " 'current state art comput',\n",
              " 'sinc earli day',\n",
              " 'we',\n",
              " 'model maxmargin',\n",
              " 'mm',\n",
              " 'natur languag process',\n",
              " 'nlp task',\n",
              " 'captur latent relationship',\n",
              " 'output languag domain',\n",
              " 'we',\n",
              " 'model',\n",
              " 'extens multiclass support vector',\n",
              " 'mation infrastructur digit librari network servic digit converg intellig agent thi attent',\n",
              " 'natur languag process',\n",
              " 'critic path kind novel applic thi articl mention number success applic natur languag process',\n",
              " 'last year',\n",
              " 'number area natur languag process',\n",
              " 'appli graphbas techniqu',\n",
              " 'other text summar',\n",
              " 'par word',\n",
              " 'sen disambigu ontolog',\n",
              " 'sentiment subject analysi text cluster',\n",
              " 'natur languag process nlp research result softwar engin softwar technolog',\n",
              " 'kernel sort increas',\n",
              " 'sever natur languag process',\n",
              " 'nlp task document match',\n",
              " 'compar corpus machin',\n",
              " 'transliter',\n",
              " 'task semisupervis variant kernel',\n",
              " 'word',\n",
              " 'sophist statist model basic element word phrase',\n",
              " 'combin structur model syntact par',\n",
              " 'analysi sinc basic properti element',\n",
              " 'paper describ framework',\n",
              " 'probabilist classifi natur languag process',\n",
              " 'our focu formul model captur import interdepend',\n",
              " 'featur avoid overfit data',\n",
              " 'data',\n",
              " 'well the class',\n",
              " 'mani natur languag process',\n",
              " 'techniqu use inform retriev',\n",
              " 'the result encourag',\n",
              " 'usual yield signific improv higherlevel process',\n",
              " 'chunk par word sen disambigu',\n",
              " 'abstract thi paper',\n",
              " 'inform retriev use natur languag process',\n",
              " 'state art plan recognit system thi paper outlin relat natur languag',\n",
              " 'processingnlp plan recognitionpr argu effect',\n",
              " 'key recent research result',\n",
              " 'nlp argu applic',\n",
              " 'state art plan recognit system thi paper outlin relat natur languag',\n",
              " 'processingnlp plan recognitionpr argu effect',\n",
              " 'key recent research result',\n",
              " 'nlp argu applic',\n",
              " 'inform retriev process',\n",
              " 'document document',\n",
              " 'satisfi inform',\n",
              " 'user',\n",
              " 'the document',\n",
              " 'natur languag',\n",
              " 'logic program',\n",
              " 'natur languag research machin',\n",
              " 'linguist knowledg',\n",
              " 'logic program keyword induct logic program natur languag process logic program machin',\n",
              " 'statist method',\n",
              " 'natur languag process nlp',\n",
              " 'paper',\n",
              " 'effect natur languag input output compon comput system',\n",
              " 'we',\n",
              " 'report collabor work field machin',\n",
              " 'ml natur languag process',\n",
              " 'the document',\n",
              " 'the first part',\n",
              " 'includ superfici comprehens survey',\n",
              " 'abstract thi thesi examin use',\n",
              " 'machin',\n",
              " 'techniqu variou task natur languag process mainli task inform extract',\n",
              " 'the object',\n",
              " 'improv adapt inform extract system new themat domain',\n",
              " 'thi chapter examin applic natur languag process computerassist languag',\n",
              " 'includ histori work field',\n",
              " 'tradit approach tointerpret natur languag process',\n",
              " 'typic',\n",
              " 'one three class syntaxdriven semanticsdriven frametask base',\n",
              " 'syntaxdriven approach',\n",
              " 'interpret process produc global par',\n",
              " 'natur languag process nlp',\n",
              " 'diver',\n",
              " 'subtop artifici intellig',\n",
              " 'a result',\n",
              " 'nlp mani subtop',\n",
              " 'includ optic charact recognit text speech',\n",
              " 'translat foreign languag',\n",
              " 'aid machin translat speech recognit',\n",
              " 'probabilist finitest string',\n",
              " 'transduc fst extrem popular natur languag process',\n",
              " 'due power gener method appli compos',\n",
              " 'unfortun',\n",
              " 'good fit',\n",
              " 'much current work probabilist model',\n",
              " 'machin',\n",
              " 'abstract',\n",
              " 'special issu tal',\n",
              " 'fundament principl underli evalu natur languag process',\n",
              " 'we',\n",
              " 'global point view',\n",
              " 'goe',\n",
              " 'horizon singl evalu campaign particular protocol',\n",
              " 'terminolog',\n",
              " 'abstract',\n",
              " 'natur languag process system nlp',\n",
              " 'clinic',\n",
              " 'textual report',\n",
              " 'effect',\n",
              " 'domain particular applic becaus nlp system',\n",
              " 'typic requir substanti resourc',\n",
              " 'benefici design easili',\n",
              " 'fact form',\n",
              " 'link',\n",
              " 'ie',\n",
              " 'natur languag process logic program prolog',\n",
              " 'we',\n",
              " 'singl convolut neural network architectur',\n",
              " 'sentenc output host languag process',\n",
              " 'partofspeech tag chunk name',\n",
              " 'tag semant role semant similar word likelihood sentenc',\n",
              " 'sen grammat',\n",
              " 'we',\n",
              " 'advanc natur languag process techniqu enhanc effect',\n",
              " 'keyword base document retriev',\n",
              " 'the backbon system statist retriev engin',\n",
              " 'autom index',\n",
              " 'abstract',\n",
              " 'paper discus sever issu requir enabl natur languag process system becom contextadapt',\n",
              " 'fact emerg system',\n",
              " 'continu speech recognit restrict',\n",
              " 'individu domain equip syntact',\n",
              " 'fall',\n",
              " 'i',\n",
              " 'appli',\n",
              " 'natur languag process student acquir',\n",
              " 'text analysi techniqu current feasibl practic applic',\n",
              " 'abstract',\n",
              " 'abstract natur languag process',\n",
              " 'studi mathemat comput model variou aspect languag',\n",
              " 'wide rang system natur languag',\n",
              " 'aris innat facil languag posse human intellect',\n",
              " 'natur languag process nlp branch artifici intellig includ speech',\n",
              " 'speech recognit machin translat natur languag process wide rang applic indian context',\n",
              " 'most rural indian commun unabl',\n",
              " 'use',\n",
              " 'an evalu lolita relat natur languag process system',\n",
              " 'univers',\n",
              " 'durham degre phd august thi research address',\n",
              " 'evalu system',\n",
              " 'lolita lolita natur',\n",
              " 'previou work demonstr web count',\n",
              " 'approxim bigram count',\n",
              " 'webbas frequenc',\n",
              " 'wide varieti natur languag process',\n",
              " 'nlp task',\n",
              " 'howev limit number task',\n",
              " 'thi chapter examin applic natur languag process computerassist languag',\n",
              " 'includ histori work field',\n",
              " 'opportun introduct thi chapter focus applic',\n",
              " 'thi paper describ natur languag system improv perform',\n",
              " 'the system process',\n",
              " 'short english narr abl',\n",
              " 'acquir',\n",
              " 'singl narr new schema stereotyp',\n",
              " 'action dure',\n",
              " 'we',\n",
              " 'review current approach softwar infrastructur research',\n",
              " 'deliveri nlp system',\n",
              " 'the task',\n",
              " 'measur practic solut',\n",
              " 'improv use natur languag process applic confid',\n",
              " 'estim gener',\n",
              " 'approach deriv confid',\n",
              " 'measur',\n",
              " 'we',\n",
              " 'overview applic confid',\n",
              " 'estim',\n",
              " 'variou field',\n",
              " 'lexsign senseid senseid dictionari ldoce lexsign',\n",
              " 'senseid senseid',\n",
              " 'ldbentryno lexsign senseid senseid',\n",
              " 'fullyfledg',\n",
              " 'integr wordspecif inform provid',\n",
              " 'thu',\n",
              " 'although neither ldoce llce',\n",
              " 'subcategoris lexicon',\n",
              " 'inform',\n",
              " 'psycholog verb defin sanfilippoaposs type system',\n",
              " 'conjunct inform',\n",
              " 'map formal represent',\n",
              " 'multilingu',\n",
              " 'a goal',\n",
              " 'acquilex demonstr',\n",
              " 'integr multilingu',\n",
              " 'the use',\n",
              " 'common lrl common type system',\n",
              " 'possi',\n",
              " 'we',\n",
              " 'design use',\n",
              " 'stanford corenlp toolkit extens',\n",
              " 'provid core natur languag',\n",
              " 'commerci',\n",
              " 'user open sourc',\n",
              " 'nlp technolog',\n",
              " 'we',\n",
              " 'gaussian process gp power model framework',\n",
              " 'incorpor kernel',\n",
              " 'bayesian infer recognis',\n",
              " 'task',\n",
              " 'a fundament issu natur languag process prerequisit enorm quantiti preprogram knowledg concern',\n",
              " 'autom acquisit',\n",
              " 'support sophist natur languag process',\n",
              " 'significantli simplifi',\n",
              " 'interfac domainspecif knowledg gener lingui',\n",
              " 'tic resourc',\n",
              " 'upper model varieti applic',\n",
              " 'neighbor map node node',\n",
              " 'view word categori',\n",
              " 'class',\n",
              " 'the central topic thesi use',\n",
              " 'the approach',\n",
              " 'thi paper present workbench',\n",
              " 'priberam informtica',\n",
              " 'compani natur languag process technolog thi workbench',\n",
              " 'number practic purpos cover',\n",
              " 'abstractnatur languag process nlp effect approach',\n",
              " 'nlp involv initi process',\n",
              " 'natur acquisit educ system',\n",
              " 'it',\n",
              " 'provid solut',\n",
              " 'abstract',\n",
              " 'twenti year',\n",
              " 'disfavor technolog',\n",
              " 'imit process brain natur languag experi sejnowski rosenberg',\n",
              " 'demonstr neural network comput architectur',\n",
              " 'text statist frequent use stylometri cryptographi studi',\n",
              " 'paper text statist tool',\n",
              " 'iso prolog natur languag process detail',\n",
              " 'usag usercal predic logic limit program',\n",
              " 'we',\n",
              " 'framenet',\n",
              " 'project natur languag process nlp',\n",
              " 'we',\n",
              " 'nlp benefit framenet',\n",
              " 'sketch problem']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Undersand TF-IDF and Document representation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(40 points). Starting from the documents (all the reviews, or abstracts, or tweets) collected for assignment two, write a python program: \n",
        "\n",
        "(1) To build the **documents-terms weights (tf*idf) matrix bold text**.\n",
        "\n",
        "(2) To rank the documents with respect to query (design a query by yourself, for example, \"An Outstanding movie with a haunting performance and best character development\") by using **cosine similarity**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: Create your own training and evaluation data for sentiment analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(15 points). **You dodn't need to write program for this question!** Read each review (abstract or tweet) you collected in detail, and annotate each review with a sentiment (positive, negative, or neutral). Save the annotated dataset into a csv file with three columns (first column: document_id, clean_text, sentiment), upload the csv file to GitHub and submit the file link blew. This datset will be used for assignment four: sentiment analysis and text classification. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMKJjIXS5G"
      },
      "source": [
        "# The GitHub link of your final csv file\n",
        "\n",
        "# Link: "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}